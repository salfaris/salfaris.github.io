---
title: "projects"
about:
  template: solana
  image-width: 10em
toc: true
---

## **üîç data science projects**

### [Financial transactions fraud detection using machine learning](https://github.com/salfaris/financial-fraud-detection)

This project covers strategy research, experimentation (with reporting) and deployment via Google Cloud.

- Researched and verified the class weight strategy in ‚ÄúFraud Detection using Machine Learning‚Äù (Oza, 2018); and further extended the paper‚Äôs analysis with new models and metrics.

- Trained logistic regression, SVMs and decision trees to perform financial transactions fraud detection in an imbalanced dataset of 6+ million rows and 0.1% sample fraud transactions (Python, scikit-learn).

- Built a web app to visualise streaming transactions data and perform live fraud detection using trained models. (Python, Streamlit, Docker, Google Artifact Registry, Google Cloud Run, Google Cloud Pub/Sub, Google Vertex AI).

---

### [Measuring the impact of a website redesign the Bayesian way](https://app.datacamp.com/workspace/w/cff27c6e-b68b-42df-ad82-9b0d029b7f0d)


*Problem statement: How can we determine if the change in observed conversion rates after website redesign is not due to random chance? Moreover, can we get an exact probability of how likely a test group is to perform better/worse than the control group?*


- In this mini project, I analysed the conversion rates of four different user groups (one of which is the control group) using pivot tables and bar plots to get a first big picture.

- Then, using PyMC3, I applied Bayesian A/B testing based on a Metropolis sampler to measure which group is most likely to have a higher conversion rate than the control group. The Bayesian way yields a solid probability unlike the frequentist approach. For example, in this project, I was able to deduce that "there is a 99% probability that user group B has a higher conversion rate than the control group".

- This exact probability gives us the confidence required to make important business decisions. In this case, we can be really confident in our decision of switching to the design version exposed to group B since there is only a 1% chance of B being worse than the control. This is one of the many awesome reasons why I favor the Bayesian approach for data tasks; this also helps us answer the second problem.

<span style="font-size:0.8em">_This project is hosted on DataCamp Workspace._</span>

---

### [Regression analysis on TfL Santander cycles](https://app.datacamp.com/workspace/w/697541bd-83ce-4ee7-809c-1bc22b3f1613)


*Problem statement: To what extent can we use a lightweight, explainable model to predict cycle hires with lowest RMSE?*


The idea of the project is to understand trends in the usage of TfL Santander Cycles (aka Boris bikes) and then predict cycle hires using linear models which are scalable and lightweight. In this project, I have

- Investigated suitability of fitting a linear model by checking existence of trends in the residuals vs fitted plot.

- Verified normality of cycle hires after Yeo-Johnson normalisation using a density, histogram and QQ plot.

- Applied feature engineering methods such as forward search model selection, one-hot encoding, moving average, and Yeo-Johnson normalisation.

- Implemented a linear model with 99% lower RMSE (935.5 to 3.5) and 155% higher R 2 score (0.27 to 0.69) relative to the baseline naive linear model.

<span style="font-size:0.8em">_This project was hosted on Deepnote and then hosted on DataCamp Workspace._</span>

---

### [Is handwashing really effective?](https://app.datacamp.com/workspace/w/fed0a2a6-1763-4433-930f-cdfc94072aec)

The Covid-19 pandemic made me want to look back at the history of handwashing when it was originally introduced. In this data exploration, we are able to answer questions like: (i) "How significant was the change between pre-handwashing era and post-handwashing era?" and (ii) "What is the 90% confidence interval of the mean of difference between these eras?".

<span style="font-size:0.8em">_This project was hosted on Deepnote and then hosted on DataCamp Workspace._</span>

<br/>

## **üíª web app projects**

### [TradeLogger](https://github.com/salfaris/tradelogger)

This project is written in Python using the Flask framework. One of the **problems with stock traders is that they do not keep the big picture of where they are in their trading journey**. For example. if they are losing, do they realise that they are losing 5 trades consecutively? This tool is designed for traders to trade better. A machine learning pipeline is also added to learn the time series pattern of whether the trader has a good chance on the next trade given the outcomes of the previous trades.

---

### [allpow](https://github.com/salfaris/allpow)

This project is written in Python using Streamlit. It is a simple calculator to estimate one's monthly budget (in London by default). I originally made it to help my fellow Malaysian students who are coming to London for the first time organise their finances better. The first problem of coming to a new country far away from home (and also most probably first time renting a property in their life) is to estimate the prices of groceries, transport, rent and the like. This calculator solves that problem.

Link to the deployed calculator: click [here](https://salfaris-allpow-app-wejo3u.streamlit.app)

<br/>

## **üîß utilities**

### [EasyPS](https://github.com/salfaris/EasyPS)

A simple, out of the box personal statement LaTeX framework. It helps handling duplicated tex files when writing personal statements for multiple universities, scholarships or jobs.

### [PyEasyPS](https://github.com/salfaris/PyEasyPS)

PyEasyPS is EasyPS (see above) ported to Python. It is even easier to use since the manual processes required in EasyPS (e.g. error-handling, targeted-updating of personal statements) are done for you. Essentially, it lets you focus on what's most important ‚Äì your personal statement content.
