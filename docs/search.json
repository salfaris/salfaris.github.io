[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "resources",
    "section": "",
    "text": "Undergraduate stuff @ KCL\n\nMy dissertation ‚Äì Diophantine Equations, supervised by Prof.¬†Payman Kassaei.\n\nI wrote my undergrad math notes in \\(\\LaTeX\\) to help me understand better. These notes can replace lecture notes and are around 100 pages long each. They can be accessed via this repository. Notable ones include:\n\n6CCM350A Rings and Modules ‚Äì based on lectures by Prof.¬†Nicholas Shepherd-Barron, Fall 2020.\n6CCM359A Numerical and Computational Methods ‚Äì based on lectures by Prof.¬†Benjamin Doyon, Fall 2020.\n5CCM224A Introduction to Number Theory ‚Äì based on lectures by Dr.¬†James Newton, Fall 2019.\n5CCM226A Metric Spaces and Topology ‚Äì based on lectures by Dr.¬†Jerry Buckley, Fall 2019.\n\n\n\nPostgraduate stuff @ Oxford\n\nMy dissertation ‚Äì ‚ÄúEnhancing VAE-learning on spatial priors using graph convolutional networks‚Äù, supervised by Seth Flaxman, Swapnil Mishra and Elizaveta Semenova.\nImplemented ‚ÄúVariational Graph Auto-Encoders‚Äù (Kipf and Welling, 2016) in JAX as part of my dissertation. Source code can be found in this repo.\nReproduced and extended ‚ÄúInference Suboptimality in Variational Autoencoders‚Äù (Cremer et. al, 2018) using JAX. Built together with Basim Khajwal, Snehal Raj and Vasileios Ntogram. Source code can be found in this repo."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "random technical thoughts.",
    "section": "",
    "text": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?\n\n\n\n\n\n\nmachine learning\n\n\ndeep learning\n\n\ncomputer vision\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nSearching for my favorite song in a deep playlist\n\n\n\n\n\n\ncombinatorics\n\n\nspotify\n\n\n\n\n\n\n\n\n\nAug 31, 2024\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nQuickest intro to random forest\n\n\n\n\n\n\nmachine learning\n\n\nensembling\n\n\n\n\n\n\n\n\n\nAug 13, 2024\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nA benchmark for testing quantum computers with Clifford+T hardware\n\n\n\n\n\n\nalgorithms\n\n\nquantum computing\n\n\nzx calculus\n\n\nbenchmarking\n\n\npython\n\n\n\nWe provide a quantum algorithm that can be used to benchmark quantum computers with Clifford+T hardware and provide a proof of the algorithm using ZX-calculus.\n\n\n\n\n\nAug 5, 2024\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nA mathematical take on when to take a loan such as ASB Financing\n\n\n\n\n\n\nquant\n\n\ninvestment\n\n\nstrategies\n\n\n\nWe look at formalizing the parity between investing with a disposable capital versus with a financed leveraged capital in ASB.\n\n\n\n\n\nApr 22, 2024\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nHow to do aws s3 ls s3://bucket/ using boto3 in python?\n\n\n\n\n\n\ncloud development\n\n\naws\n\n\npython\n\n\n\n\n\n\n\n\n\nMar 12, 2023\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nClash Series: Checking Number is Prime\n\n\n\n\n\n\nclash of code\n\n\nalgorithms\n\n\npython\n\n\n\n\n\n\n\n\n\nMar 5, 2022\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nPreparing Image Dataset for Neural Networks in PyTorch\n\n\n\n\n\n\nmachine learning\n\n\ncomputer vision\n\n\npytorch\n\n\ndata preprocessing\n\n\n\n\n\n\n\n\n\nSep 7, 2021\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nThe Coding Kata\n\n\n\n\n\n\nsoftware engineering\n\n\nclean coding\n\n\n\n\n\n\n\n\n\nAug 18, 2021\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nPlotly.py main theme in Plotly.js\n\n\n\n\n\n\njavascript\n\n\nplotly\n\n\npython\n\n\nweb dev\n\n\n\n\n\n\n\n\n\nJun 13, 2021\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nUnit Testing with pytest\n\n\n\n\n\n\npython\n\n\ntesting\n\n\nsoftware engineering\n\n\n\nWhy do we do unit testing and how to do unit testing in python using pytest.\n\n\n\n\n\nMay 3, 2021\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nRelational Databases in Python (part I)\n\n\n\n\n\n\ndata science\n\n\npython\n\n\nsql\n\n\nsqlalchemy\n\n\ndatabases\n\n\ndata handling\n\n\n\n\n\n\n\n\n\nApr 30, 2021\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nMaking pastel-colored boxes using tcolorbox in LaTeX\n\n\n\n\n\n\nlatex\n\n\nwriting\n\n\n\n\n\n\n\n\n\nApr 7, 2021\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nRoot-hunting algorithm: Newton‚Äôs method\n\n\n\n\n\n\nnumerical analysis\n\n\nalgorithms\n\n\n\n\n\n\n\n\n\nApr 5, 2021\n\n\nSalman Faris\n\n\n\n\n\n\n\n\n\n\n\n\nBlogging again\n\n\n\n\n\n\ngeneral\n\n\n\n\n\n\n\n\n\nApr 5, 2021\n\n\nSalman Faris\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-04-30-relational-databases-in-python-part-I/index.html",
    "href": "posts/2021-04-30-relational-databases-in-python-part-I/index.html",
    "title": "Relational Databases in Python (part I)",
    "section": "",
    "text": "Post header\nWe usually hear the word databases being thrown around especially when talking about data-related things. So what is it, and what is the more precise term relational databases?\nA relational database is like an Excel file. It is made up of tables (note that this is plural) which holds data in the form of columns and rows. In the Excel analogy, tables are basically sheets. Moreover, tables can be related to each other but they need a column to act as a bridge linking them. Such a column is usually called a key (either primary key or foreign key). This feature of being related explains the relational term in relational databases. Relational databases is part of the relational model which is a much more general framework of structuring and handling data management.\nFrom now on, we shall simply refer to relational databases as just databases."
  },
  {
    "objectID": "posts/2021-04-30-relational-databases-in-python-part-I/index.html#introduction-to-sqlalchemy",
    "href": "posts/2021-04-30-relational-databases-in-python-part-I/index.html#introduction-to-sqlalchemy",
    "title": "Relational Databases in Python (part I)",
    "section": "Introduction to SQLAlchemy",
    "text": "Introduction to SQLAlchemy\npip install sqlalchemy\nGreat, we now know what databases are, but how do we work with them? If this is an Excel file, we just open it and the rest is obvious (at least we think it‚Äôs obvious because we‚Äôre used to working with it). How do we open and interact with a database? There are many ways to do this and there‚Äôs no one right way. For example, you can work directly with SQLite or MySQL in the command line but things can really get messy if you do it this way.\nIf you‚Äôre using Python, then enter SQLAlchemy! SQLAlchemy gives you the power of interacting with databases using SQL queries straight from Python. Plus, it helps us abstract away complex queries and the difference in databases (remember that there are a lot of popular databases e.g.¬†MySQL, PostgreSQL and Oracle with subtle differences among them). So querying databases becomes cleaner (and more exciting?) via SQLAlchemy. To install SQLAlchemy is as easy as executing the line of code you see below this section‚Äôs title in your favorite terminal. If you‚Äôre using Anaconda, then it is already shipped and ready to use!\nAdditional notes:\n\nThis is not an excuse to not learn writing raw SQL queries because understanding SQL is still important when working with tools like SQLAlchemy!\nThose of you who have built web applications with Flask or Django might realize that we usually handle data using an object-oriented approach ‚Äì using so-called data models. This is the Object Relational Model (ORM) approach, which is one of the two main components of SQLAlchemy. The other main component is called the ‚Äúcore part‚Äù of SQLAlchemy which is really centred around the relational model of the database. The latter is the one that we will be focusing on in this post today."
  },
  {
    "objectID": "posts/2021-04-30-relational-databases-in-python-part-I/index.html#talking-to-a-database-first-steps",
    "href": "posts/2021-04-30-relational-databases-in-python-part-I/index.html#talking-to-a-database-first-steps",
    "title": "Relational Databases in Python (part I)",
    "section": "üí¨ Talking to a database, first steps",
    "text": "üí¨ Talking to a database, first steps\n\nStep 1: Create an engine\nTo write something on a paper, you would need a pencil. To turn the lights on, you would need to switch the toggle. To interact with a database, you would need a so-called engine.\nIn theory, a database relies on this engine just like how a car would rely on its (car) engine. But I found that thinking of this engine as a mediator rather than a literal engine is much easier to digest.\nTo create an engine, you first have to import the create_engine function from sqlalchemy. Then, you need to pass in a connection string which in its simplest form specifies two things: (i) the database you want to talk to, and (ii) the path to the database. For example, if I want to connect to race_data.db which is a SQLite database in my current directory, the connection string would be \"sqlite:///race_data.db\". So together, they would look something like this:\nengine = create_engine(\"sqlite:///race_data.db\")\n\nKey terms\n\nThe engine is a mediator for SQLAlchemy to interact with a database.\nA connection string specifies the details of the database we want to interact with.\n\n\n\n\nStep 2: Establish a connection\nIn the previous step, we have simply created an engine but have yet to connect to it! To establish a connection, you can simply invoke another one-liner:\nconnection = engine.connect()\nOne thing worth pointing out is that SQLAlchemy is clever enough to not actually make a connection until we pass in some queries for it to execute.\n\n\nStep 3: Checking table names\nRecall that tables are to databases just like sheets are to Excel files. So you‚Äôd want to know what tables (not columns of a table, yet!) are available before making queries. To do this, you can simply execute\nprint(engine.table_names())\nto get a list of available tables to work with. For me, this returns\n&gt;&gt;&gt; ['race_table']\nwhich means that I have only one table named 'race_table'. In practice, you would usually have a few tables."
  },
  {
    "objectID": "posts/2021-04-30-relational-databases-in-python-part-I/index.html#querying-the-database-using-sqlalchemy",
    "href": "posts/2021-04-30-relational-databases-in-python-part-I/index.html#querying-the-database-using-sqlalchemy",
    "title": "Relational Databases in Python (part I)",
    "section": "üìù Querying the database using SQLAlchemy",
    "text": "üìù Querying the database using SQLAlchemy\nFrom now on, we assume that we have instantiated an engine and connection object exactly like what we did previously.\n\nRaw SQL queries, ResultProxy and ResultSet\nRecall that we use the SQL language to make CRUD operations ‚Äì create, read, update and delete. If you are not familiar with this, I highly recommend that you learn a bit of SQL after reading this - my recommendation is Mike Dane‚Äôs{:target=‚Äú_blank‚Äù} free and complete SQL course, from installing MySQL to joining tables. However, for now, it is sufficient to know the ‚ÄúHello World‚Äù of SQL ‚Äì which is SELECT * FROM this_table where this_table is some table in the database. The query SELECT * FROM this_table does exactly what you expect it to do, it selects every possible row (symbolized by the asterisk *) in the table this_table and returns it to the user. In my case, with my race_data.db database, I would want to execute SELECT * FROM race_table. So how would I do this with SQLAlchemy? This is where connection from Step 2 comes in.\nThe connection object has a method .execute() which can execute raw SQL queries like SELECT * FROM race_table. This will then return a ResultProxy object which can be utilized in various ways to get the data we want (based on our query). Here are some examples of how we would want our data:\n\nSometimes, we know our query will return a unique result (e.g.¬†because we query based on a unique ID), so it is trivial that we want the first and only result;\nSometimes, we want the whole result;\nSometimes, we want only the top 10.\n\nImagine processing 500k rows of data just because we want the top 10, not so efficient right? This is why we would want a two-layer process before getting our actual data, the first layer being the ResultProxy object. Getting the actual data from the ResultProxy object is simply a matter of invoking a method. For example, if we would want to get the whole result, we use the .fetchall() method. If we want the top 10 result, we use the .fetchmany() method with size argument set to 10. Invoking these methods returns a ResultSet object, which basically contains the data we want. Here is an example of a complete implementation:\nq = \"SELECT * FROM race_table\"\nresult_proxy = connection.execute(q)  # ResultProxy\nresults = result_proxy.fetchmany(size=10)  # ResultSet\n\nQuerying data in Python is a two-layer process:\n\nA ResultProxy gives us flexibility to access the data that we queried ‚Äì do you want 1, 10 or 500k?.\nA ResultSet contains the actual data that we queried, retrieved via a ResultProxy method.\n\n\n\n\nWorking with ResultSet\nThe ResultSet results is a list of tuples whose entries corresponds to columns in the table. Let‚Äôs get the first row in results. Since it is a list, we do this by accessing the zeroth element in the list via row = results[0]. We can print the row to get the actual data, a tuple with entries:\n&gt;&gt;&gt; (1, 88, 0.95, 1, 5, 436, '2013-11-03 13:19:25')\nTo get the column names that correspond to each entry, we can invoke row.keys() to get:\n&gt;&gt;&gt; ['Race #', 'WPM', 'Accuracy', 'Rank', '# Racers', 'Text ID', 'Date/Time (UTC)']\nIf we already know which column of interest we want to look at for a particular row, we can access the attribute of the row just like how we would normally do to access the value of a key in a dictionary. For example, if I‚Äôm interested in knowing the Accuracy of this row, I would just execute either row.Accuracy or row[\"Accuracy\"] which returns 1 as expected.\n\n\nSQLAlchemy queries\nI know I promised that SQLAlchemy can help abstract away complex SQL queries and database differences, and using raw SQL queries like we did so far doesn‚Äôt seem to agree with this promise. Enter SQLAlchemy‚Äôs neat and Pythonic way of querying using table reflection.\nA table reflection or just reflection is basically a process which reads the desired database, looks for your desired table and copies it into a Table object (see below) as if you wrote a whole raw SQL query to create this table. Personally, the term reflection is quite misleading for me and I would more prefer the term autocopy ‚Äì because that is literally what the process does, and my philosophy is that explicit is better than nano-misleadings.\nTo make a reflection, you would need to import two classes from the sqlalchemy library: MetaData and Table. It is worth understanding a basic idea of what these things do:\n\nThe MetaData class can be thought of a folder or catalog that keeps information about database stuffs such as tables. In this way, we don‚Äôt have to keep looking up table information because we have ‚Äúorganized‚Äù things nicely.\nThe Table class does exactly what you expect it to do. It stores and handles the reflected (i.e.¬†autocopied) version of your desired table so that SQLAlchemy can interact with it.\n\nNow we know the required ingredients, let‚Äôs see how to actually do a table reflection. Recall that we have instantiated an engine and connection object from the previous section. We now instantiate a MetaData object via metadata = MetaData(); and then instantiate a Table object passing the arguments:\n\nOur desired table; in my case, \"race_table\" (this is a string, cf.¬†Step 3 of checking table names).\nThe instantiated metadata.\nSet autoload to True, and put autoload_with our engine.\n\nOverall, it should look like this:\nfrom sqlalchemy import MetaData, Table\nmetadata = MetaData()\n\n# Table reflection\nrace_table = Table(\"race_table\", metadata, autoload=True, autoload_with=engine)\nThe first thing you might want to do then is to use the repr function on race_table to learn our table‚Äôs details such as the column names together with their types such as REAL, INTEGER or TEXT. Mine returns this:\n&gt;&gt;&gt; Table('race_table', MetaData(bind=None), Column('Race #', INTEGER(), table=&lt;race_table&gt;), Column('WPM', INTEGER(), table=&lt;race_table&gt;), Column('Accuracy', REAL(), table=&lt;race_table&gt;), Column('Rank', INTEGER(), table=&lt;race_table&gt;), Column('# Racers', INTEGER(), table=&lt;race_table&gt;), Column('Text ID', INTEGER(), table=&lt;race_table&gt;), Column('Date/Time (UTC)', TEXT(), table=&lt;race_table&gt;), schema=None)\nThe true power of the SQLAlchemy way of querying comes now. To replicate our raw SQL query of SELECT * FROM race_table, we can import and use the select function from the sqlalchemy library. The select function can take a (list of) Table object to select all the rows in that table. The equivalent query to SELECT * FROM race_table is then select([race_table]). More completely, we execute the following code:\nq = select([race_table])\nresult_proxy = connection.execute(q)  # ResultProxy\nresults = result_proxy.fetchmany(size=10)  # ResultSet\nObserve that the last two lines are identical as to when we were writing raw SQL queries, the only difference being the first line. Hence, the way we access results is exactly the same as we‚Äôve discussed earlier. For the SELECT query, it might be trivial to use the select function but you can imagine that when the queries gets more complex, this will be really nice and clean. Note that you can get the raw SQL query of q by simply printing it to the console.\nReferences\n\n[1] Introduction to Databases in Python, DataCamp\n[2] Sam Hartman‚Äôs Answer to Understanding MetaData() from SQLAlchemy in Python, Stack Overflow"
  },
  {
    "objectID": "posts/2021-09-07-preparing-image-dataset-in-pytorch/index.html",
    "href": "posts/2021-09-07-preparing-image-dataset-in-pytorch/index.html",
    "title": "Preparing Image Dataset for Neural Networks in PyTorch",
    "section": "",
    "text": "Preparing and handling data is a core step of any machine learning pipeline. Today, we will look at handling data when the data is an image (or image-like) in PyTorch.\n\nPyTorch and Torchvision\nPyTorch provides us with the amazing torchvision package for dealing with common image transformations such as normalizing, scaling, random flipping and converting arrays to PyTorch tensors. It also provides us with common computer vision datasets such as MNIST, Fashion MNIST and CIFAR-10. In this post, we will focus on preparing the Fashion MNIST dataset.\nTo begin, we start by importing torch and torchvision.\nimport torch\nfrom torchvision import datasets, transforms\n\nNote that we will refer to the submodule datasets and transforms directly from now on (i.e.¬†we will not emphasize that it‚Äôs part of torchvision).\n\n\n\nüëú Fashion MNIST dataset and composing transformations\nThe Fashion MNIST dataset by Zalando Research is a famous benchmark dataset in computer vision, perhaps second only to MNIST. It is a dataset containing 60,000 training examples and 10,000 test examples where each example is a 28 x 28 grayscale image. Since the images are in grayscale, they only have a single channel. If the image is in RGB format instead (e.g.¬†if we are dealing with CIFAR-10), then it has 3 channels one for each red, green and blue.\nAs mentioned before, the Fashion MNIST dataset is already part of PyTorch. However, this does not mean that the dataset is already in perfect shape to pass into a PyTorch neural net. We would need to apply some (image) transformations to the dataset upon fetching. For brevity, we will apply only two simple transformations:\n\nConverting the images to a PyTorch tensor ‚Äì by using transforms.ToTensor().\nNormalize the channel of the resulting tensor ‚Äì by using transforms.Normalize().\n\nWhy do we do these transformations?\n\nSince we will be working with neural nets in PyTorch, it is only natural that we want the image to be a PyTorch tensor. This enables the PyTorch API to interact properly with our dataset.\nNormalization is important to ensure that our neural nets learn better. For an idea of how normalization works, check out this discussion.\n\nWe can then compose these transformations using transforms.Compose() as below.\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5), std=(0.5)),\n])\n\nNote that the mean and standard deviation value of 0.5 should be calculated from the training set in advance. Here, we just assume that mean = std = 0.5 for simplicity.\n\n\n\nüíæ From dataset to DataLoader\nThe next step is to finally fetch the dataset, passing our transform above as an argument. The FashionMNIST dataset can be accessed via datasets.FashionMNIST, no surprise there. We can then fetch the 60,000 training examples using the following code:\ntrainset = datasets.FashionMNIST(root='./data',\n                                 download=True,\n                                 train=True,\n                                 transform=transform)\nLet us break down what each argument means.\n\nroot specifies the location of the dataset. Here, we specify that it should be in the directory './data'.\ndownload is a boolean flag which determines if we want to download the dataset if the data is not already in root.\ntrain is another boolean flag which determines if we want the training set. Getting the test set is as simple as passing train=False.\ntransform is the transformations we would like to apply to the dataset upon fetching.\n\nOnce we have our transformed train set, we can now start training neural nets on this data using PyTorch. However, let us take a second to think about the following:\n\nWhat if we want to work with minibatches of this dataset instead of single examples? This is definitely a need when the dataset is too large like ours to be trained entirely.\nWe would also want to reshuffle this dataset on each epoch so that our neural net generalizes better.\nIf the data is big, we might even want to load the data in parallel using multiprocessing workers to retrieve our data faster.\n\nThis is where PyTorch‚Äôs so-called DataLoader comes in. It is an iterable that provides all the above features out of the box on top of providing a smooth API for working with data!\nTo use the DataLoader object on our train set, we simply access torch.utils.data.DataLoader and feed trainset into it.\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n                                          shuffle=True, num_workers=0)\nHere, we have decided to use a batch_size of 64 images, which are sampled randomly on each epoch due to shuffle=True. We also put num_workers=0 meaning we are not loading the data in parallel.\nWe can fetch the Fashion MNIST test dataset in a similar fashion. The only difference is that we now have train=False.\ntestset = datasets.FashionMNIST(root='./data',\n                                download=True,\n                                train=False,\n                                transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64,\n                                         shuffle=True, num_workers=0)\n\n\nüïµÔ∏è Inspecting the dataset in DataLoader form\nOnce we have the dataset in DataLoader form, we can start inspecting our dataset. For example, we can get the shapes of our trainset.\nprint(\"Train shape:\", trainloader.dataset.data.shape)\nprint(\"Test shape:\", testloader.dataset.data.shape)\nTrain shape: torch.Size([60000, 28, 28])\nTest shape: torch.Size([10000, 28, 28])\nWe can also get the minibatch size as specified when initializing the DataLoader.\nprint(\"Train batch size:\", trainloader.batch_size)\nprint(\"Test batch size:\", testloader.batch_size)\nTrain batch size: 64\nTest batch size: 64\nFor a more advanced inspection, we can even look at the sampler and the collate function used in the DataLoader. The sampler determines how the data is shuffled and the collate function specifies how the data is batched.\nprint(\"Sampler:\", trainloader.sampler)\nprint(\"Collate function:\", trainloader.collate_fn)\nSampler: &lt;torch.utils.data.sampler.RandomSampler object at 0x7fcc02b23b90&gt;\nCollate function: &lt;function default_collate at 0x7fcc05c9a710&gt;\nSince we did not pass anything during initialization, we get the default RandomSampler object for the sampler and the default default_collate collate function as expected.\nAs we are dealing with an image dataset, it is a shame if we are not plotting anything during inspection. Let‚Äôs plot the first image from the first batch in trainloader.\nimages, labels = next(iter(trainloader))  # Gets a batch of 64 images in the training set\nfirst_image = images[0]  # Get the first image out of the 64 images.\n\nimport matplotlib.pyplot as plt\nplt.imshow(first_image.numpy().squeeze(), cmap='Greys_r')\nplt.show()\nHere, we get a t-shirt which is expected since we are dealing with a fashion dataset after all. If you run the exact code, you might get a different output since the dataset is shuffled and I did not specify a seed.\n\n\n\nPlot of image from Fashion MNIST\n\n\nFor the simplified version of this post in jupyter notebook format: notebook version."
  },
  {
    "objectID": "posts/2021-04-05-first-post/index.html",
    "href": "posts/2021-04-05-first-post/index.html",
    "title": "Blogging again",
    "section": "",
    "text": "I‚Äôve been an active blogger since 2011 up until 2016 (although most of the earlier contents are now hidden due to cringiness) where I talked about various things ‚Äì life events, some tech stuff and my scholarship interview experiences. I stopped blogging when I started my International Baccalaureate (IB) diploma program. Throughout my undergraduate years, I channelled most of my writing energy answering IB questions on Quora and writing my notes using LaTeX. Today, I‚Äôve decided to start blogging again, focusing on math, statistics and ML.\nDo note that in the early stages of this blog, the contents might be inconsistent or quite random. This is because I am still finding the right pace and momentum in writing and generating content. Thanks for understanding!"
  },
  {
    "objectID": "posts/2021-06-13-plotly-theme-in-react-plotly-js/index.html",
    "href": "posts/2021-06-13-plotly-theme-in-react-plotly-js/index.html",
    "title": "Plotly.py main theme in Plotly.js",
    "section": "",
    "text": "If you‚Äôre like me who is used to using Plotly.py (i.e.¬†Plotly Python) and then suddenly decided to use Plotly.js directly, you might immediately realize that there are some significant differences in terms of the plot design.\n\n\n\nPlotly Python Plot\n\n\nFor one, your default plot in Plotly.js has a white background and not the steel blue colour as you would expect from a default Plotly.py plot. The reason is that the plots produced in the python version of Plotly come prepackaged with nice out-of-the-box themes. For example, the plot image above is a Plotly.py scatter plot with the default plotly template. So how do we reproduce these themes inside of Plotly.js?\nDiving deeper into the Plotly documentation, I discovered that you can actually get the ‚Äútheme settings‚Äù for the Plotly.py templates with just 4 lines of Python code.\nimport plotly.io as pio\ntemplate = \"plotly\"\nplotly_template = pio.templates[template]\nprint(plotly_template.layout)\nThe Python code above prints the ‚Äútheme settings‚Äù of the plot or in proper Plotly lingo, the plot layout settings. In our particular case above where we set template = \"plotly\", we get the default plotly theme layout settings:\nLayout({\n    'annotationdefaults': {'arrowcolor': '#2a3f5f', 'arrowhead': 0, 'arrowwidth': 1},\n    'autotypenumbers': 'strict',\n    'coloraxis': {'colorbar': {'outlinewidth': 0, 'ticks': ''}},\n    ...\n})\nAs you can see, it is in serialized JSON format. The idea now then is to deserialize this layout settings into a JavaScript object literal and pass it into the layout of your plot in Plotly.js. I did the deserialize process manually because I cannot find a way to automate this process (I would love to hear if you are able to do it!). For the default plotly theme, the JavaScript object literal is given below:\n\n\nNote: Stating the obvious but since the layout setting is extracted from the Plotly documentation, it is the hard work of the people behind Plotly. Thank you for the awesome theme!\n\nThe final step is to pass this layout into the layout parameter of the Plotly plot, and you get your favorite default Plotly.py theme again but now directly in Plotly.js!"
  },
  {
    "objectID": "posts/2021-08-18-coding-kata/index.html",
    "href": "posts/2021-08-18-coding-kata/index.html",
    "title": "The Coding Kata",
    "section": "",
    "text": "A coding kata is an exercise to sharpen your programming skills and muscle memory via repetition. I learnt this concept when I was reading The Clean Coder (highly recommended!) and have since adopted it as part of my programming routine. It helps my hands ‚Äúknow‚Äù what to type when I need to type.\nI have also adapted the concept of kata as a means to learn/revise programming languages effectively. Instead of writing a random script doing god knows what after learning the syntax, I would implement the simple linear regression algorithm from scratch in this language. Why this is a good kata you ask? Here is why among others:\n\nYou can practice using OOP in the new lang\nYou will deal with ints, doubles, static and dynamic arrays.\nYou will do some basic math operations.\nYou will implement at least one function.\nYou will implement at least a for loop.\nYou might use an import.\n\nTo put simply, it ensures you use a lot of the functionalities in the language and actually spend time doing it.\nI recently wanted to refresh my mind on the C++ lang and I also want to reinforce my JavaScript knowledge. So here‚Äôs my linear regression implementation in these two languages (although the way data is expected is a bit different in the JS implementation compared to the C++ implementation).\n\nC++JavaScript\n\n\n#include &lt;vector&gt;\nusing namespace std;\n\nclass LinearRegression {\n    private:\n        int m_epoch;\n        double m_learningRate;\n        vector&lt;double&gt; weights;\n\n    public:\n        LinearRegression(int epoch, double learningRate) {\n            this-&gt;m_epoch = epoch;\n            this-&gt;m_learningRate = learningRate;\n        }\n\n        void fit(vector&lt;double&gt; x, vector&lt;double&gt; y) {\n            vector&lt;double&gt; weights = {0, 0};\n            int dataLength = x.size();\n\n            int epoch = this-&gt;m_epoch;\n            for (int e = 0; e &lt; epoch; e++) {\n                for (int i = 0; i &lt; dataLength; i++) {\n                    double estimate = weights[0] + x[i]*weights[1];\n                    double error = y[i] - estimate;\n\n                    weights[0] += this-&gt;m_learningRate * error;\n                    weights[1] += this-&gt;m_learningRate * error * x[i];\n                }\n            }\n\n            this-&gt;weights = weights;\n        }\n\n        vector&lt;double&gt; predict(vector&lt;double&gt; x) {\n            int dataLength = x.size();\n            vector&lt;double&gt; yPred;\n            yPred.reserve(dataLength);  // Preallocate length of yPred based on size of x.\n\n            vector&lt;double&gt; weights = this-&gt;weights;\n            for (int i = 0; i &lt; dataLength; i++) {\n                yPred.push_back(weights[0] + x[i]*weights[1]);\n            }\n\n            return yPred;\n        }\n};\n\n\nclass LinearRegression {\n  constructor(params = {}) {\n    this.weights = params.weights || [];\n    this.learningRate = params.learningRate || 0.01;\n    this.data = [];\n    this.fittedValues = [];\n  }\n\n  estimator(x, weights) {\n    const [w0, w1] = weights;\n    return w0 + x * w1;\n  }\n\n  fit(data) {\n    this.data = data;\n    if (this.weights === undefined || this.weights.length === 0) {\n      this.weights = [0, 0];\n    }\n\n    for (let i = 0; i &lt; this.data.length; i++) {\n      const { x, y } = this.data[i];\n\n      const estimate = this.estimator(x, this.weights);\n      const error = y - estimate;\n\n      let [w0, w1] = this.weights;\n\n      w0 += this.learningRate * error;\n      w1 += this.learningRate * error * x;\n\n      this.weights = [w0, w1];\n    }\n\n    this.fittedValues = this.getFittedValues();\n  }\n\n  getFittedValues() {\n    return this.data.map(({ x, y }) =&gt; {\n      return { x: x, y: this.estimator(x, this.weights) };\n    });\n  }\n}\n\n\n\nI leave the Python implementation to you ;)"
  },
  {
    "objectID": "posts/2024-08-30-searching-song-in-deep-playlist/index.html",
    "href": "posts/2024-08-30-searching-song-in-deep-playlist/index.html",
    "title": "Searching for my favorite song in a deep playlist",
    "section": "",
    "text": "TLDR; Keep your playlists small. There‚Äôs a 50% chance of finding your favourite song in less than or equal to 4 steps in a playlist of length 9. With each additional song in your playlist, you decrease the speed of finding your favourite song by roughly 10%.\nI love music. I listen to music all the time and I especially listen to music when I go running, where I would put it on shuffle mode. Now a few runs ago, I was aggressively double tapping my airpods to jump to the next song, skipping a lot of songs in the process until it reaches a song that I was keen on listening to at that moment. That‚Äôs when I started thinking, given that I started at a particular song in the playlist, can I quantify how many steps do I need to take to reach a particular favourite song in my playlist?\nNow it is important to note that modern music streaming services like Spotify do not necessarily implement naive shuffle functions which samples the next song uniformly at random. It is more likely that they implement a weighted shuffle function which samples the next music with replacement, assuming some weight on the song based on, for example, popularity of the song (global recommendation approach) or occurrence of listening to the song (a personalized approach). For the sake of this problem, however, we will assume that the songs in the playlist are shuffled uniformly at random.\nThere are many ways to approach this problem (which is the beauty of this problem). For example, one can form a complete digraph for the songs in the playlist, remove the directed path from your favourite song to any other node (but keep the inverse so that your favourite song is a sink) and then count the number of all possible paths between any node (song) and the target favourite song. Note that this is different to finding a shortest path which we have Dijsktra‚Äôs algorithm for. That algorithm runs in O\\left(|E| + |V| \\log |V| \\right) time where E is the multiset of edges and V the set of nodes. Rather, the problem of finding the number of paths is much harder and would not have an algorithm that enjoy such speeds.\nInstead of the graph approach, I will go down the dark hole known as combinatorics. The downside is that the setup will be less natural and will require some level of abstraction. The upside, however, is that once everything is set up nicely, solving the problem essentially amounts to careful counting. Let‚Äôs start seeing an example on how we can do this."
  },
  {
    "objectID": "posts/2024-08-30-searching-song-in-deep-playlist/index.html#painting-paths-in-a-playlist",
    "href": "posts/2024-08-30-searching-song-in-deep-playlist/index.html#painting-paths-in-a-playlist",
    "title": "Searching for my favorite song in a deep playlist",
    "section": "Painting paths in a playlist",
    "text": "Painting paths in a playlist\nSuppose a playlist contains three songs s_1, s_2, s_T. Let‚Äôs ask the most basic question of how many paths can I reach the target song s_T? Now the answer is not 3!=6 because you can reach s_T without visiting all the other songs in the playlist. For example, you can reach s_T via the route s_1 \\to s_T or s_2 \\to s_T respectively. In total, you can reach s_T in 5 different ways. These are:\n\ns_T \\to s_T\ns_1 \\to s_T\ns_2 \\to s_T\ns_1 \\to s_2 \\to s_T\ns_2 \\to s_1 \\to s_T\n\nwhere the first path s_T \\to s_T is the tautological path of starting and ending at s_T.\nHow about if the playlist contain four songs s_1, s_2, s_3, s_T, how many paths can I reach the target song s_T? You should be convinced by now that the answer is not 4!=24, but how many? The answer is that there are 16 paths in total. For your sanity, I will enumerate this long list below:\n\ns_T \\to s_T\ns_1 \\to s_T\ns_2 \\to s_T\ns_3 \\to s_T\ns_1 \\to s_2 \\to s_T\ns_2 \\to s_1 \\to s_T\ns_3 \\to s_2 \\to s_T\ns_2 \\to s_3 \\to s_T\ns_1 \\to s_3 \\to s_T\ns_3 \\to s_1 \\to s_T\ns_1 \\to s_2 \\to s_3 \\to s_T\ns_2 \\to s_1 \\to s_3 \\to s_T\ns_3 \\to s_2 \\to s_1 \\to s_T\ns_2 \\to s_3 \\to s_1 \\to s_T\ns_1 \\to s_3 \\to s_2 \\to s_T\ns_3 \\to s_1 \\to s_2 \\to s_T.\n\nNow you should start to see a pattern. In both cases where the playlist is of length three and four, we observe that the target song s_T remains fixed and the only thing that changes is the order of the songs prior to s_T. Further, the number of songs that are reordered is progressively unconstrained to acknowledge that you can reach the target song in an increasing number of steps. Thus, the number of paths to reach the target song s_T is just a sum of k-permutations of n-1 songs where k is the number of steps allowed to reach s_T and n is the length of the playlist. This sum is done from 0, which represents the tautological path s_T \\to s_T, up to n-1 which represents a permutation of the path s_1 \\to s_2 \\to \\cdots \\to s_{n-1} \\to s_T. This argument essentially is a proof of the following result.\n\n\nProposition 1 (Number of paths given playlist) The number of paths to reach the target song s_T in a playlist \\mathcal{P} of length n is given by: N(n; \\mathcal{P}) = \\sum_{j=0}^{n-1} P(n-1, j).\nwhere P(m, k) is the k-permutation of m objects.\n\n\nIn the case of n=4 that we have just enumerated above, the number of steps is given by:\n\nN(4) = P(3, 0) + P(3, 1) + P(3, 2) + P(3, 3) = 1 + 3 + 6 + 6 = 16\n\nwhich agrees with our brute-force enumeration. Similarly, you can check that N(3) = 5 as we have enumerated before.\nSo this is a good result, but it has not answer our main question:\n\nGiven a song s in playlist \\mathcal{P}, how many ways can you reach your favourite song s_T \\in \\mathcal{P} in less than or equal to t \\in \\mathbb{Z}^+ steps?\n\nIt has, however, answered the easier question:\n\nGiven a playlist \\mathcal{P}, how many ways can you reach your favourite song s_T \\in \\mathcal{P} in less than or equal to t \\in \\mathbb{Z}^+ steps?\n\nThis question is answered by using Proposition¬†1 and simply truncating the summation at t \\leq n-1.\nThe difference between the main question and this easier question is that the former essentially wants N | s, \\mathcal{P} whereas what we have at the moment gives N | \\mathcal{P}. So let‚Äôs move towards a solution, suppose we start at a song s \\in \\mathcal{P}, what then?"
  },
  {
    "objectID": "posts/2024-08-30-searching-song-in-deep-playlist/index.html#answering-the-main-question",
    "href": "posts/2024-08-30-searching-song-in-deep-playlist/index.html#answering-the-main-question",
    "title": "Searching for my favorite song in a deep playlist",
    "section": "Answering the main question",
    "text": "Answering the main question\nI have been using the term playlist quite loosely throughout this article so let‚Äôs make it concrete. A playlist \\mathcal{P} of length n is simply a finite set of songs \\{ s_1, s_2, \\ldots, s_{n-1}, s_T\\}. It does not assume any ordering, and our logic does not assume ordering unless mentioned otherwise. This definition aligns with what we had before and so the result(s) remain.\nAs per Proposition¬†1, we know that N(4) = 16 and reaching the target song in less than or equal to k \\leq n-1 steps is given by \\sum_{j=0}^{k} P(n-1, j). These makes no assumption on where we start the path at. Suppose now you start at song s_3 in the playlist. How many paths can you take take to reach your target song s_T? Let‚Äôs start enumerating all the possible paths to reach s_T again, but this time we highlight how many steps it takes to reach s_T from s_3.\n\ns_T \\to s_T (impossible)\ns_1 \\to s_T (impossible)\ns_2 \\to s_T (impossible)\ns_3 \\to s_T (1)\ns_1 \\to s_2 \\to s_T (impossible)\ns_2 \\to s_1 \\to s_T (impossible)\ns_3 \\to s_2 \\to s_T (2)\ns_2 \\to s_3 \\to s_T (1)\ns_1 \\to s_3 \\to s_T (1)\ns_3 \\to s_1 \\to s_T (2)\ns_1 \\to s_2 \\to s_3 \\to s_T (1)\ns_2 \\to s_1 \\to s_3 \\to s_T (1)\ns_3 \\to s_2 \\to s_1 \\to s_T (3)\ns_2 \\to s_3 \\to s_1 \\to s_T (2)\ns_1 \\to s_3 \\to s_2 \\to s_T (2)\ns_3 \\to s_1 \\to s_2 \\to s_T (3).\n\nTo argue easier, we first make the following definition.\n\n\nDefinition 1 (t-path) Let \\mathcal{P} be a playlist of length n. A t-path from s_j \\in \\mathcal{P} is a path that starts at s_j and ends at s_T \\in \\mathcal{P} in t \\in \\mathbb{Z}^+ steps.\nIt is trivially non-unique as we have seen. So we denote the number of t-paths from s_j by N_t(n; s_j). If the dependence on s_j is obvious, we simply write N_t(n).\nHere are some examples. s_1 \\to s_T is a 1-path from s_1. Another example is that s_3 \\to s_4 \\to s_1 \\to s_T is a 2-path from s_4 and a 1-path from s_1.\n\n\nBack to our enumeration of the playlist of length 4, we observe firstly that there are some impossible paths where s_3 is not visited at all. Then you have five 1-paths to reach s_T from s_3, four 2-paths and two 3-paths.\nJust focusing on 1-paths here, it is easy to see that the number of 1-paths to reach s_T from s_3 is given by N(n-1) because we can ‚Äúgroup‚Äù s_3 \\to s_T together and treat it as a single end point s_T'. It is also easy to see that the number of 3-paths is essentially a permutation on songs that are left, which in this case is 2! = 2. It is tempting now to say that the case of 2-paths is simply N(n-1) - 1 since we are discarding the unique s_3 \\to s_T case which exists only for 1-paths and that everything else is just a permutation of the remaining songs; and you are not wrong to think so as we shall see! The problem is that it does not give a strong explanation for what a general pattern would be.\nSo let‚Äôs look at a playlist of length n=5 and count each t-path from s_4. At this point enumeration of the playlist can get a bit crazy as we know by Proposition¬†1 that there are N(5) = 65 paths to reach s_T from s_4. I highly recommend you enumerate these paths by writing code (I‚Äôve provided a fugly python code to do this in the appendix. See Listing¬†1). Now if we focus on each t-paths, we see that there are\n\n16 counts of 1-paths,\n15 counts of 2-paths,\n12 counts of 3-paths,\n6 counts of 4-paths.\n\nAs we have observed before, the number of 1-paths is indeed N(n-1) = N(4) = 16. Discard the unique s_4 \\to s_T path and we have 15 count of 2-paths. And that the number of 4-paths is just a permutation on songs that are left giving us (5-2)! = 3! = 6. So how do we explain the 12 counts of 3-paths? Now a 3-path from s_4 would look like the following\n\n\\textcolor{blue}{\\rule{1.8ex}{1.8ex}} \\to s_4 \\to \\rule{1.8ex}{1.8ex} \\to \\rule{1.8ex}{1.8ex} \\to s_T,\n\nwhere the \\textcolor{blue}{\\rule{1.8ex}{1.8ex}}, \\rule{1.8ex}{1.8ex} are placeholders for other songs. Let‚Äôs start counting and consider parity. If we assume \\textcolor{blue}{\\rule{1.8ex}{1.8ex}} is null, i.e., we start at s_4, then there are P(3, 2) possible ways to fill in \\rule{1.8ex}{1.8ex}, and hence, P(3, 2) number of steps to reach s_T. On the other hand, if we assume \\textcolor{blue}{\\rule{1.8ex}{1.8ex}} is not null, i.e., the path starts at one of s_1, s_2, s_3, then there are P(3, 3) possible ways to fill in \\textcolor{blue}{\\rule{1.8ex}{1.8ex}}, \\rule{1.8ex}{1.8ex}. So in total, the number of 3-paths is P(3, 2) + P(3, 3) = 12 which is what we observed in the enumeration!\nIn fact, we can run this same argument for all the other t-paths as well. For a 4-path from s_4, we would have the following sequence\n\ns_4 \\to \\rule{1.8ex}{1.8ex} \\to \\rule{1.8ex}{1.8ex} \\to \\rule{1.8ex}{1.8ex} \\to s_T.\n\nIn this case, it is trivial to see that there are P(3, 3) = 6 ways to fill in the \\rule{1.8ex}{1.8ex} boxes.\nFor 2-paths, we have the following sequence\n\n\\textcolor{green}{\\rule{1.8ex}{1.8ex}} \\to \\textcolor{blue}{\\rule{1.8ex}{1.8ex}} \\to s_4 \\to \\rule{1.8ex}{1.8ex} \\to s_T.\n\nIf we assume both \\textcolor{green}{\\rule{1.8ex}{1.8ex}}, \\textcolor{blue}{\\rule{1.8ex}{1.8ex}} to be null, then there are P(3, 1) possible ways to fill in \\textcolor{black}{\\rule{1.8ex}{1.8ex}}. The case where \\textcolor{blue}{\\rule{1.8ex}{1.8ex}} is null but \\textcolor{green}{\\rule{1.8ex}{1.8ex}} is not null is impossible, so suppose only \\textcolor{green}{\\rule{1.8ex}{1.8ex}} is null. Then there are P(3, 2) possible ways to fill in \\textcolor{blue}{\\rule{1.8ex}{1.8ex}}, \\textcolor{black}{\\rule{1.8ex}{1.8ex}} with songs. And finally if \\textcolor{green}{\\rule{1.8ex}{1.8ex}} not null, then there are P(3, 3) ways to fill in \\textcolor{green}{\\rule{1.8ex}{1.8ex}}, \\textcolor{blue}{\\rule{1.8ex}{1.8ex}}, \\textcolor{black}{\\rule{1.8ex}{1.8ex}}. Thus in total, we have P(3, 1) + P(3, 2) + P(3, 3) = 15 paths to reach s_T.\nThe 1-path case is just considering an additional box \\textcolor{red}{\\rule{1.8ex}{1.8ex}} that can take a null value and running the same argument should lead you to 16 steps in total. It should not be difficult to see how we can generalize this pattern to arbitrary playlists of length n so I leave the proof as an exercise for you to do.\nSuch a proof would yield the following result.\n\n\nTheorem 1 (Number of t-paths) Let \\mathcal{P} be a playlist of length n. Given a starting song s \\in \\mathcal{P} and a target song s_T \\in \\mathcal{P}, the number of t-paths from s to s_T is given by:\n\n% N_{\\text{t-path}}(t, n; s, s_T) = \\sum_{j=0}^{n-1-t} P(n-2, n-2-j).\nN_{t}(n) = \\sum_{j=0}^{n-1-t} P(n-2, n-2-j).\n\n\n\nThis is a great result as it gives us a way to compute the number of paths to reach a song in a playlist of length n in exactly t steps. As a consequence, we can now compute the number of paths to reach a song in a playlist of length n in less than or equal to t steps.\n\n\nCorollary 1 (Number of paths to reach favourite song in \\leq t steps) Let \\mathcal{P} be a playlist of length n. Given a starting song s \\in \\mathcal{P} and a target song s_T \\in \\mathcal{P}, the number of paths to reach s_T in less than or equal t \\in \\mathbb{Z}^+ steps is given by:\n\nN_{\\leq t}(n) = \\sum_{\\ell=1}^{t} N_{\\ell}(n).\n\n\n\nWhat‚Äôs great about Corollary¬†1? Well it gives a satisfying answer to our main question of\n\nGiven a song s in playlist \\mathcal{P}, how many ways can you reach your favourite song s_T \\in \\mathcal{P} in less than or equal to t \\in \\mathbb{Z}^+ steps?\n\nwhich is all that we wanted. To see this in practice, fix t=4 to consider the number of paths to reach your favourite song in less than or equal to 4 steps. Then we look at N_{\\leq t} with varying n in the range 5 \\leq n \\leq 14. We will also consider the probability of reaching your favourite song in less than or equal to t steps by computing N_{\\leq t}/N(n). The numbers are tabulated below.\n\n\n\n\n\n\n\n\n\nn\nN_{\\leq t}\n\\lfloor \\log N_{\\leq t}\\rfloor\nN_{\\leq t}/N(n)\n\n\n\n\n5\n49\n1\n0.75\n\n\n6\n237\n2\n0.73\n\n\n7\n1271\n3\n0.65\n\n\n8\n7783\n3\n0.57\n\n\n9\n54741\n4\n0.50\n\n\n10\n438329\n5\n0.44\n\n\n11\n3945547\n6\n0.40\n\n\n12\n39456291\n7\n0.36\n\n\n13\n434020313\n8\n0.33\n\n\n14\n5208245221\n9\n0.31\n\n\n\nIt is not suprising to see that with increasing number of playlist length n, the number of paths N_{\\leq t} increases dramatically. In fact, as we have computed with \\lfloor \\log N_{\\leq t} \\rfloor, the order of magnitude increases roughly by one at every increasing length n. The probability, however, does not decrease as dramatically, so you still have a good chance of finding your favourite songs with ease.\nToday, I have a playlist with 53 songs. The number of possible paths to reach my current favourite song in this playlist in less than or equal to t=4 steps given an abitrary starting song is\n\n16865511683372560412495381946812946399349813999270471596889656524800 \\sim 10^{67}\n\npaths which is on the order of 67. This is an exorbitantly huge number with 67 zeros. If we were to compute N_{\\leq t}/N(n), we get 7.7% which is honestly not too bad. But still‚Ä¶ an 8% chance of finding my favourite song is quite low. Moral of the story? Try to make your playlists small."
  },
  {
    "objectID": "posts/2024-08-30-searching-song-in-deep-playlist/index.html#what-next",
    "href": "posts/2024-08-30-searching-song-in-deep-playlist/index.html#what-next",
    "title": "Searching for my favorite song in a deep playlist",
    "section": "What next?",
    "text": "What next?\nHere are some key directions we can take to explore.\n\nWhat if instead of a single target favourite song s_T, we have a set of target songs \\{s_{T_1}, s_{T_2}, ...\\}. How will the analysis differ when we start at any arbitrary song? This seems easy‚Ä¶ I think.\nSimilarly, what if instead of a single starting song s, we have a set of arbitrary starting songs \\{s_1, s_2, ...\\}. How will the number of paths change?\nDo a precise analysis on the order of growth in the number of paths. If you divide N_{\\leq t} for n with n-1 successively, you will see that the growth is factorial. This is kind of expected but can you prove it? It is easy to see that the growth in the total number of paths is factorial by using Proposition¬†1, but how about for paths up to t steps?\nDo a precise analysis on N_{\\leq t}/N(n). Seems like there‚Äôs approximately a ~90% drop for the numbers that we have tabulated as n increases. Finding a bound would be excellent.\nI‚Äôm pretty sure we can try solving this problem using group theory.\nConsider weighted shuffle on playlists now, how would you solve the same problem? Maybe a graph approach is inevitable?"
  },
  {
    "objectID": "posts/2024-08-30-searching-song-in-deep-playlist/index.html#appendix",
    "href": "posts/2024-08-30-searching-song-in-deep-playlist/index.html#appendix",
    "title": "Searching for my favorite song in a deep playlist",
    "section": "Appendix",
    "text": "Appendix\n\nEnumerating playlist of length n\nThe code below enumerates a playlist of length n but it is highly inefficient. A back of the envelope estimate gives me a rough O(n!) time complexity. Can you do better?\n\n\n\nListing¬†1: Enumerate playlist of length n=4\n\n\nfrom itertools import permutations\n\nNULL = 0\nE = -1\n\n\ndef enum(seq: list[int]) -&gt; set[tuple[int, ...]]:\n    n = len(seq)\n\n    pool = set(range(1, n + 1))\n\n    # Find indexes where values are not empty.\n    # Since we only care about permutations, values are unique at each index (except\n    # for the NULL value). So remove encountered filled values from the permutation\n    # pool.\n    filled_idxs: list[int] = []\n    for idx, v in enumerate(seq):\n        if v != E:\n            filled_idxs.append(idx)\n            pool.remove(v)\n\n    # Make pool into a list because we may append &gt;=1 NULLs to it.\n    pool = list(pool)\n    # The least index of filled values determine the number of NULLs possible for\n    # the permutations.\n    for _ in range(min(filled_idxs)):\n        pool.append(NULL)\n    all_perm = list(permutations(pool, r=(n - len(filled_idxs))))\n    all_perm = set(all_perm)  # remove dups\n\n\n    # Find invalid NULL configurations such as (NULL, 1, NULL, ...). NULLs cannot\n    # appear after valid positive integer.\n    bad_seqs = set()\n    for p in all_perm:\n        num_found = False\n        for i in p:\n            if i != NULL:\n                num_found = True\n                continue\n            if num_found and i == NULL:\n                bad_seqs.add(p)\n                break\n\n    # Sucks this is python and you have to do something like this\n    assert isinstance(all_perm, set), \"`all_perm` is not a set.\"\n\n    good_seqs = all_perm - bad_seqs\n    return good_seqs\n\n\nif __name__ == \"__main__\":\n\n    def generate_new_seq(n: int):\n        new_seq = []\n        init = [E] * n\n        init[-1] = n\n        for i in range(n - 2, E, E):\n            init[i] = n - 1\n            if i != n - 2:\n                init[i + 1] = E\n            new_seq.append(init.copy())\n        return new_seq\n\n    seqs = generate_new_seq(5)\n\n    full_enumeration = []\n    for seq in seqs:\n        valid_perms = enum(seq)\n        for perm_seq in valid_perms:\n            seq2 = seq.copy()\n            idx = 0\n            for i in perm_seq:\n                while seq2[idx] != E:\n                    idx += 1\n                seq2[idx] = i\n            full_enumeration.append(seq2)\n\n    full_enumeration.sort()\n    N = len(full_enumeration)\n    warn_out = (\n        \"WARNING: Note that we use '0' as NULL pointers in the following enumeration.\"\n    )\n    print(\"-\" * len(warn_out))\n    print(warn_out)\n    print(\"-\" * len(warn_out))\n    for e in full_enumeration:\n        print(e)\n    print()\n    print(f\"N_t({len(seq)}) = {N}\")"
  },
  {
    "objectID": "posts/2021-05-03-unit-testing-with-pytest/index.html",
    "href": "posts/2021-05-03-unit-testing-with-pytest/index.html",
    "title": "Unit Testing with pytest",
    "section": "",
    "text": "It is a common scene that we want to test our functions after we‚Äôve done writing them. In Python, we can usually do this by printing to the console. For example, suppose we are interested in testing the following function:\nwhich returns the sum of the two integers x and y if the output is strictly positive, or else return None. Since we are adding two positive integers, we expect that the add_positive function returns a positive integer as well. So we can try a few pairs, say, add_positive(2, 3) and add_positive(1, 1), and we expect these to return 5 and 2 respectively; both greater than 0. If we try add_positive(-1, -5), then this should return None as it yields -6 instead which is less than 0. If we want to test our function with multiple inputs, we can do something like a for loop. So maybe something like:\nwhich should yield\nand then we eyeball each of the output to see if it as expected.\nThis is of course a correct way to do it as we can evaluate whether the output on the console is as expected; but is it efficient?"
  },
  {
    "objectID": "posts/2021-05-03-unit-testing-with-pytest/index.html#why-unit-testing-is-a-no-brainer",
    "href": "posts/2021-05-03-unit-testing-with-pytest/index.html#why-unit-testing-is-a-no-brainer",
    "title": "Unit Testing with pytest",
    "section": "üß† Why unit testing is a no-brainer",
    "text": "üß† Why unit testing is a no-brainer\nIn a typical life cycle of a function, there are three situations where we would want to test our functions:\n\nThe first time it is implemented.\nWhen a test fails, we fix the bug, and then we have to redo testing.\nWhen implementing a new feature or refactoring code.\n\nImagine how many times we would have to manually test this function. If it would take 3 minutes per (manual) test, and if we would have to do it 100 times over the function‚Äôs whole life cycle, then we would have effectively spent 3 x 100 = 300 minutes, which is roughly 5 hours of testing! Now if we have 10 functions to test, it would take us 50 hours or roughly 2 days worth of time to test these functions! I don‚Äôt know about you, but that sounds like a lot of time to me for only 10 functions. This is why we would want to automate the testing process by writing unit tests, which, together with the planning phase, requires about an hour to write in perpetuity (in theory).\n\nManually testing a function throughout its whole life cycle may take you 5 hours; whereas writing a properly planned unit test may take you only an hour, and this is one-fifth of the former.\n\nThere are a variety of Python libraries to do unit testing, some of which are:\n\npytest\nunittest\nnosetests\ndoctest"
  },
  {
    "objectID": "posts/2021-05-03-unit-testing-with-pytest/index.html#basic-unit-testing-procedure",
    "href": "posts/2021-05-03-unit-testing-with-pytest/index.html#basic-unit-testing-procedure",
    "title": "Unit Testing with pytest",
    "section": "üß™ Basic unit testing procedure",
    "text": "üß™ Basic unit testing procedure\nIn this post, we will look at pytest because it is simply the most popular (hence, a lot of support, say, on StackOverflow) and easiest to use. We start by installing pytest if it‚Äôs not already installed:\npip install pytest\n\nStep 1: Creating the test module\nAssume that the add_positive() function lies in a module called add_positive.py. We begin the unit testing process by creating a file called test_add_positive.py in the same directory as add_positive.py. Such a file will contain the unit tests of functions in add_positive.py, and is called a test module. The test_ in front of test_add_positive.py is important as it lets pytest knows that this is a file containing unit tests.\n_Remark: The test module for the module add_positive.py does not have to be named test_add_positive.py. You can name it test_x.py or test_covid.py or whatever as long as it is prepended with test_. But it is good practice to follow the naming convention of test*module_name to trace which module is this test module testing.*\n\n\nStep 2: Importing inside the test module\nThe next step is to (mainly) import two things:\n\nThe pytest module;\nand the module (or function) we want to test.\n\nSo at the top of our test module test_add_positive.py, we would have:\nimport pytest\nfrom add_positive import add_positive\n\n\nStep 3: Begin writing unit tests\nA unit test is basically a Python function, no more and no less. The only thing special about a unit test is that it is prepended by test_ in its name. This is just to tell pytest to use it as part of the testing procedure. Here is an example of a unit test declaration:\ndef test_for_positive_pairs():\n    ...\nInside the body of a unit test are assertions, and this is the actual testing process. We want to test if our add_positive() function returns correctly if positive pairs (x, y) are passed into the function. So we assert the following:\ndef test_for_positive_pairs():\n    assert add_positive(3, 5) == 8\n    assert add_positive(99999, 99999) == 199998\nHow about if we want to add a second unit test which tests when a zero pair i.e.¬†(0, 0) is passed into the function? Well we just write another function right below it. We expect add_positive(0, 0) to return None, so we write exactly that:\ndef test_for_positive_pairs():\n    assert add_positive(3, 5) == 8\n    assert add_positive(99999, 99999) == 199998\n\ndef test_for_zero_pair():\n    assert add_positive(0, 0) is None\nI would like to add two more tests which test the add_positive function when negative and mixed pairs are fed into the function. The whole test module should now look something like this:\nimport pytest\nfrom add_positive import add_positive\n\ndef test_for_positive_pairs():\n    assert add_positive(3, 5) == 8\n    assert add_positive(99999, 99999) == 199998\n\ndef test_for_negative_pairs():\n    assert add_positive(-1, -6) is None\n    assert add_positive(-99, -99) is None\n\ndef test_for_zero_pair():\n    assert add_positive(0, 0) is None\n\ndef test_for_mixed_pairs():\n    assert add_positive(-1, 2) == 1\n    assert add_positive(-9, 100) &gt; 0\n    assert add_positive(-900, 2) is None\nRemark: Note that you can get as creative as you‚Äôd like with the values you‚Äôre testing. It is good practice to always consider edge cases in the unit test, but this is a topic of a later post.\n\n\nStep 4: Running pytest and reading the test report\nOnce you‚Äôre done with writing the test module, testing is as easy as opening your terminal, cd-ing into the directory containing the test module, and executing:\npytest test_add_positive.py\nIf the implementation of add_positive() is correct (with respect to our tests), you should see a test report like this.\n\n\n\nPass test\n\n\nJust ignore everything above ‚Äúcollected 4 items‚Äù as it is not too important. The breakdown of this test report is the following:\n\n‚ÄúCollected 4 items‚Äù means that we will be executing 4 unit tests.\nThe 4 green dots indicates that we have pass all 4 of them, and they are sequential (see what happens when 1 fail below).\nThe obvious ‚Äú4 passed in 0.02s‚Äù message is the summary."
  },
  {
    "objectID": "posts/2021-05-03-unit-testing-with-pytest/index.html#why-unit-tests-are-important-in-prod",
    "href": "posts/2021-05-03-unit-testing-with-pytest/index.html#why-unit-tests-are-important-in-prod",
    "title": "Unit Testing with pytest",
    "section": "üìå Why unit tests are important in prod",
    "text": "üìå Why unit tests are important in prod\nThree months after the add_positive.py code has been deployed, your colleague Gilfoyle modified the add_positive() function returning only the sum:\ndef add_positive(x, y):\n    \"\"\"Add two positive integers x and y. If the sum\n     is negative or zero, return None.\"\"\"\n    return x + y\nApparently, he didn‚Äôt read the short description of the function; he thought that you‚Äôre adding an unnecesary check. However, the function is supposed to work like that ‚Äì only returning if the sum is positive (think of another module which relies on the correctness of this function).\nIf there were no unit tests written to check this modification, this seemingly trivial edit by Gilfoyle could have been merged into the main branch and could possibly crash the whole system! Thankfully, we implemented continuous integration and upon making a pull request, Gilfoyle was bombarded with the following test report:\n\n\n\nFail test\n\n\nHere is a breakdown of the report:\n\n‚ÄúCollected 4 items‚Äù means the same as before.\nThe first green dot means we passed the first unit test, but the subsequent F‚Äôs means we failed the second, third and fourth unit test;\nthis is reflected in the FAILURES section below it, showing which exact lines contribute to these failures.\nThe ‚Äú3 failed, 1 passed in 0.19s‚Äù message is the summary.\n\nSometimes, we just want to run the test up until the first failure. This can be done by adding a -x flag like so:\npytest -x test_add_positive.py\nNow you might be wondering, what to do if we have multiple functions to test in the same module given that this one single add_positive function alone requires 4 unit tests. Things can start getting really messy right? To solve this issue, we can create a class containing these unit tests for each function we want to test. This will be a topic of a future post on testing."
  },
  {
    "objectID": "posts/2024-08-04-quantum-fibonacci/index.html",
    "href": "posts/2024-08-04-quantum-fibonacci/index.html",
    "title": "A benchmark for testing quantum computers with Clifford+T hardware",
    "section": "",
    "text": "I was revisiting some of my MSc stuff from two years ago and I came across one of my original work in Quantum Processes and Computations (QPC). It was one of the funner courses I took ‚Äì I had a genuine interest in the hype behind quantum computing at the time and the prerequisite for the course was just simple linear algebra. Aleks Kissinger taught the course and he‚Äôs incredibly passionate about the subject and is also a good explainer. He was also the one who interviewed me to get into the program where he randomly asked me about my favourite theorem in Galois Theory, really peeking my interest to the point of ‚Äúwhat the heck are they cooking in the quantum computing group‚Äù but that‚Äôs another story.\nIn QPC, a part of the take-home ‚Äúexam‚Äù was to produce anything interesting using the ZX-calculus. Bonus points if it‚Äôs original, has a strong motivation and/or has a rigorous proof. ‚ÄúOriginal‚Äù here was a bit vague in the sense that various parts can be original ‚Äì the idea, implementation, proof, etc. I remember just spending several days trying to figure out what to do ‚Äî really went deep into theorems in number theory, for example, and I manage to land on something original and provided a working proof, but not so much on good motivation I confess. Ultimately, I decided to keep it simple and build on a Fibonacci heuristic proposed in (Gilliam, Pistoia, and Gonciulea 2020), where I modified the routine they wrote, implemented it in the ZX-calculus and proved that the algorithm is correct. The routine relies solely on Clifford+T gates and because of the simplicity of the Fibonacci algorithm (as we shall see), it ought to serve as a good benchmarking tool for quantum computers with hardware that accepts only Clifford+T gates.\nBefore I go any further, I have to warn you that this is neither an introduction to quantum computing nor ZX-calculus. What I can tell you is that ZX-calculus gives you superpowers for reasoning in quantum computing. If you want a primer on both at the same time, check out (Coecke and Kissinger 2017) which is where I learnt all the basics from. Another good resource is John‚Äôs ZX-calculus primer ZX-calculus for the working quantum computer scientist. John van de Wetering is also one of the guys who taught QPC alongside Aleks. I realize that nowadays, there‚Äôs also less dense intros to the subject as well like this one at PennyLane."
  },
  {
    "objectID": "posts/2024-08-04-quantum-fibonacci/index.html#what-does-combinatorics-tells-us-about-fibonacci-numbers",
    "href": "posts/2024-08-04-quantum-fibonacci/index.html#what-does-combinatorics-tells-us-about-fibonacci-numbers",
    "title": "A benchmark for testing quantum computers with Clifford+T hardware",
    "section": "What does combinatorics tells us about Fibonacci numbers?",
    "text": "What does combinatorics tells us about Fibonacci numbers?\nDefine a recurrence relation F_n = F_{n-1} + F_{n-2} with initial conditions F_0=1 and F_1 = 2 where n &gt; 1. The positive integers F_n generated by this recurrence relation is universally known today as the Fibonacci sequence 1, 2, 3, 5, 8, 13, ... and so on. At this point, it is not straightforward how we can encode this relation into a quantum circuit. So how do we encode this information to perform quantum computation? If I learn anything from my short stint of constructing quantum algorithms, you can always end up with a working algorithm by converting the problem into a counting problem. If you have a counting problem, you can perform what is called heuristic encoding where you can design a quantum circuit that ‚Äúgenerates‚Äù the things you want to count, run the circuit repeatedly for a sufficiently long period, and then count the number of measurement outcomes, possibly with some required classical post-processing.\nFor the Fibonacci numbers, combinatorics tells us that there is an equivalence between the Fibonacci numbers and the number of length n binary sequences with no consecutive ones where this equivalence is given as F_n = \\left|B^n \\right| where\nB^n = \\left\\{ x \\in \\{0,1\\}^n : x \\text{ has no consecutive ones} \\right\\}.\nWith this formulation of the Fibonacci numbers, we now have a counting problem rather than a recurrence problem where we can perform heuristic encoding! So let‚Äôs now turn our attention to constructing a quantum routine that generates elements of B^n."
  },
  {
    "objectID": "posts/2024-08-04-quantum-fibonacci/index.html#building-a-quantum-routine-for-generating-elements-of-bn",
    "href": "posts/2024-08-04-quantum-fibonacci/index.html#building-a-quantum-routine-for-generating-elements-of-bn",
    "title": "A benchmark for testing quantum computers with Clifford+T hardware",
    "section": "Building a quantum routine for generating elements of B^n",
    "text": "Building a quantum routine for generating elements of B^n\nLet‚Äôs think about this from the ground up and consider n=2. How can we generate elements of B^2? Enumerating B^2 gives us the set\nB^2 = \\left\\{ 00, 01, 10 \\right\\},\nwhere it‚Äôs missing the sole binary sequence 11 \\in \\{ 0, 1\\}^2. One way to think about this is to build a quantum routine that generates the outcomes \\ket {00}, \\ket {01}, \\ket {10} but not \\ket {10}. To achieve this, you want a 2-qubit system such that\n\nqubit 1 admits equal superposition when measured; but\nqubit 2 to be in equal superposition only if the first qubit is in the state \\ket {0}.\n\nAn easy way to do this is to use two X_{\\pi/2} rotation gates together with a single CX_{\\pi/2} controlled rotation gate where X_{\\pi/2} is a 2x2 matrix given by\nX_{\\pi/2} = \\begin{pmatrix} \\cos{\\pi/4} & -i \\sin{\\pi/4} \\\\ -i \\sin{\\pi/4} & \\cos{\\pi/4} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 \\\\ 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix},\nand CX_{\\pi/2} is a 4x4 matrix given by CX_{\\pi/2} = \\begin{pmatrix} I_2 & 0 \\\\ 0 & X_{\\pi/2} \\end{pmatrix}.\nHere I_2 is the 2x2 identity matrix and 0 is a block 2x2 matrix of zeros. For a sanity check, you can evaluate the product\n (CX_{\\pi/2})  (X_{\\pi/2} \\otimes X_{\\pi/2})  (\\ket {0} \\otimes \\ket {0})\nto see that we indeed have a quantum state that yields binary sequences in B^2. Here, \\otimes is the Kronecker product induced by the tensor product of linear maps. If you are lazy, you can skip the sanity check as we are going to prove this using ZX-calculus next anyways which will be much simpler and more elegant, especially for the general case.\nNow we go to n=3 and enumerate B^3. Here we have the set\nB^3 = \\left\\{ 000, 001, 010, 100, 101 \\right\\},\nwhere it‚Äôs missing the binary sequences 110 and 111 that has two and three consecutive ones respectively. As before, think about state outcomes. It is slightly complicated as you now have 2^3 potential outcomes. However, if you think inductively, there is a pattern here. In this case, we now want\n\nqubit 1 to be in equal superposition;\nqubit 2 to be in equal superposition only if qubit 1 is in the state \\ket {0}; and\nqubit 3 to be in equal superposition only if qubit 2 is in the state \\ket {0}.\n\nIn this case, we end up with outcomes exactly as in B^3. Observe that the control on qubit 3 is dependent only on the measurement of qubit 2. This means that we can reuse the same principle we had in the case of n=2. In fact, we can simply extend the previous routine by introducing an X_{\\pi/2} rotation gate on qubit 3 and a single CX_{\\pi/2} controlled rotation gate which conditions on qubit 2.\nFurther observe that qubit 2 is dependent only on the measurement of qubit 1. Thus going from the n=2 case to n=3 is simply extending qubit 3 with 2 new rotation gates. It should be clear that we can reuse this same principle to go from n=3 to n=4 and so on; so we conjecture the following:\n\nConjecture: For n &gt; 1, B^n can be generated by an n-bit quantum routine that performs X_{\\pi/2} rotation gates to all qubits n and then applying n-1 controlled rotation gates CX_{\\pi/2} such that the jth controlled rotation gate conditions on qubit j-1 for j &gt; 2.\n\nSo how do we go about proving this conjecture? Well, it‚Äôs time to turn to ZX-calculus."
  },
  {
    "objectID": "posts/2024-08-04-quantum-fibonacci/index.html#fibonacci-in-the-zx-calculus",
    "href": "posts/2024-08-04-quantum-fibonacci/index.html#fibonacci-in-the-zx-calculus",
    "title": "A benchmark for testing quantum computers with Clifford+T hardware",
    "section": "Fibonacci in the ZX-calculus",
    "text": "Fibonacci in the ZX-calculus\nA short note before we proceed. It has been incredibly hard to embed tikz files (which I originally wrote all my ZX diagrams in) into a HTML format, so I will be taking screenshots from my original solution for my sanity ‚Äì I‚Äôve already wasted 3 hours trying, please believe me. I hate low quality screenshots as well so if you have an elegant solution on how to do this, please let me know.\nI claim that the following ZXFibo algorithm is a working n-bit quantum routine that generates B^n for n &gt; 1, and hence the Fibonacci sequence F_n.\n\nAlgorithm. ZXFibo\n\nGiven. An integer n &gt; 1, for the Fibonacci number F_n to be computed.\nPerform.\n\n\n\n\n\nwhere the process \\widehat{f_n} is given by\n\n\n\n\n\nwhere\n\n\n\n\n\nis called the y-box (since it topologically looks like a Y, sorry I‚Äôm clearly not creative with my naming).\nMeasuring this circuit yields an outcome of 0 up to a number for Z-measurement outcomes \\ket {k_1 \\ldots k_n} with consecutive ones and not 0 (up to a number) otherwise.\n\nIt shouldn‚Äôt be too difficult to see that the process \\widehat{f_n} given above is indeed equivalent to spamming X_{\\pi/2} rotations and putting a control CX_{\\pi/2} gate on each qubit. But if you‚Äôre not convinced or your ZX-calculus is rusty, I‚Äôll probably do it as an appendix at some point. What‚Äôs important, however, is to recognize that the process only uses Clifford+T gates.\nNow, let‚Äôs prove that the ZXFibo algorithm is correct. It‚Äôs a counting algorithm, so naturally we prove by induction on n. But before we start, let‚Äôs recall some of the spider rules in ZX-calculus. Core to this proof are the copy rule (c), commute rule (\\pi) and the eliminate rule (e) given below:\n\n\n\n\n\nThe commute rule is especially used when k = 0. We can also combine the commute rule, the eliminate rule and phase spider fusion to arrive at what I like to call the (\\alpha \\pi) rule:\n\n\n\n\n\nThe (\\alpha \\pi) rule is an important one and we will be using it several times in our correctness proof of ZXFibo. With these rules refreshed, we are ready to prove the base case.\nBase case. For n=2, just using definitions of \\widehat{f_2} and the y-box \\widehat{y}, and using phase spider fusion, we get\n\n\n\n\n\nWe can then look at individual measurement outcomes. For k, \\ell \\in \\{0, 1\\} we have\n\n\n\n\n\nThen using spider fusion, the colour change rule and the copy rule, we end up with\n\n\n\n\n\nWe can now apply the (\\alpha \\pi) rule to end up with\n\n\n\n\n\nFrom here, we can evaluate each pair (k, \\ell) separately. Recall what these spiders actually mean ‚Äì the representation of an undoubled phase state \\alpha \\in \\mathbb{C}^2 is given by the matrix\n\n\n\n\n\nwhere the phase effect version is simply attained by taking the adjoint of the phase state matrix. This implies that\n\n\n\n\n\nConsequently, the undoubled number\n\n\n\n\n\ncan be tabulated into the following table of numbers and their corresponding complex amplitudes\n\n\n\n\n\nIn particular the measurement outcome pair (k, \\ell) = (1, 1) attains a zero complex amplitude. Moreover, where k and \\ell are not both 1, the amplitude is nonzero. This is exactly what we want and so completes the base case. In fact, you can actually get the actual probabilities pretty easily from here, but we leave it as an exercise for the reader.\n\nExercise. Show that the actual probabilities for each measurement outcome are tabulated as follows:  Hint: look at the complex amplitudes of the doubled version.\n\nInductive step. Now suppose that the ZXFibo algorithm is correct for all 2 \\leq n &lt; N + 1. Then for n = N+1, we can look at individual measurement outcomes k_1, \\ldots, k_{N+1} \\in \\{0, 1\\} to have\n\n\n\n\n\nWe can apply the copy rule on the N-th measurement so that we have\n\n\n\n\n\nThe inductive hypothesis takes care of the evaluated \\widehat{f_N}, so we know that it will not be 0 up to a number for Z-measurement outcomes \\ket {k_1 \\ldots k_N} with no consecutive ones. So now we focus on the rightmost y-box. To complete the inductive step, we just need to prove that if k_N = k_{N+1} = 1, then the y-box evaluates to 0, and not 0 otherwise.\nUsing the y-box definition, applying phase spider fusion and using the colour change rule, we have\n\n\n\n\n\nWe can then apply the eliminate rule and the (\\alpha \\pi) rule to further obtain\n\n\n\n\n\nThis number is exactly what we had before with \\ell = k_{N+1} and k = k_N. Thus by using the same logic as we did before, we can conclude that the pair (k_N, k_{N+1}) = (1, 1) which gives the only remaining measurement outcome with consecutive ones will evaluate the whole diagram to 0 (up to a number) and not 0 otherwise. This completes the inductive step and the correctness proof of the ZXFibo algorithm. As a bonus, we have also implicitly proven that the algorithm terminates for all qubits n &gt; 1. \\blacksquare"
  },
  {
    "objectID": "posts/2024-08-04-quantum-fibonacci/index.html#zxfibo-on-an-ibm-quantum-computer",
    "href": "posts/2024-08-04-quantum-fibonacci/index.html#zxfibo-on-an-ibm-quantum-computer",
    "title": "A benchmark for testing quantum computers with Clifford+T hardware",
    "section": "ZXFibo on an IBM quantum computer",
    "text": "ZXFibo on an IBM quantum computer\nNow that we have proven the correctness of the ZXFibo algorithm, let‚Äôs see how it performs on an IBM quantum computer simulator. We will implement ZXFibo using the IBM Qiskit library (Javadi-Abhari et al. 2024) and the PyZX library (Kissinger and Wetering 2020) which we import below.\n\n\nPyZX and IBM Qiskit base imports\nimport math\nfrom fractions import Fraction\n\nimport pyzx as zx\nfrom pyzx import print_matrix\nfrom pyzx.basicrules import *\nzx.settings.drawing_backend = 'matplotlib'\n\nimport qiskit\nfrom qiskit.test.mock import FakeAthens\nfrom qiskit import QuantumCircuit, Aer, IBMQ, execute\nfrom qiskit.compiler import assemble\nfrom qiskit.tools.monitor import job_monitor\n\nimport matplotlib.pyplot as plt\n\n\nWe can then draw ZXFibo using PyZX as follows.\n\ndef add_cx_alpha_gate(\n    circuit: zx.Circuit, alpha: Fraction | int, control: int, target: int\n) -&gt; zx.Circuit:\n    circuit.add_gate(\"HAD\", target)\n    circuit.add_gate(\"ZPhase\", control, phase=alpha * Fraction(1, 2))\n    circuit.add_gate(\"ZPhase\", target, phase=alpha * Fraction(1, 2))\n    circuit.add_gate(\"CNOT\", control, target)\n    circuit.add_gate(\"ZPhase\", target, phase=alpha * Fraction(-1, 2))\n    circuit.add_gate(\"CNOT\", control, target)\n    circuit.add_gate(\"HAD\", target)\n    return circuit\n\n\ndef zxfibo(n: int, graph: bool = False) -&gt; zx.Circuit:\n    circ = zx.Circuit(n)\n    # For each qubit, add an X(\\pi/2) gate.\n    for i in range(n):\n        circ.add_gate(\"XPhase\", i, Fraction(1, 2))\n    # For each qubit n &gt; 1, add a controlled X(\\pi/2) gate.\n    for i in range(n - 1):\n        add_cx_alpha_gate(circ, Fraction(-1, 2), i, i + 1)\n    if graph:\n        return circ.to_graph()\n    return circ\n\nGiven a PyZX circuit, we can convert it into a Qiskit circuit using the following function (I believe this was Aleks‚Äôs code).\n\ndef pyzx_to_qiskit(circ: zx.Circuit) -&gt; qiskit.QuantumCircuit:\n    # converts all gates to CNOT, CZ, HAD, ZPhase, and XPhase\n    circ = circ.to_basic_gates()\n    q = circ.qubits\n    ibm_circ = QuantumCircuit(q, q)\n    for g in circ.gates:\n        if isinstance(g, zx.gates.CNOT): ibm_circ.cnot(g.control, g.target)\n        elif isinstance(g, zx.gates.CZ): ibm_circ.cz(g.control, g.target)\n        elif isinstance(g, zx.gates.HAD): ibm_circ.h(g.target)\n        elif isinstance(g, zx.gates.ZPhase): ibm_circ.rz(math.pi * g.phase, g.target)\n        elif isinstance(g, zx.gates.XPhase): ibm_circ.rx(math.pi * g.phase, g.target)\n    \n    # measure everything\n    ibm_circ.measure(range(q), range(q))\n    return ibm_circ\n\nFor the base case n=2 of ZXFibo, we can then obtain its ZX-diagram and Qiskit quantum circuit by running:\nzxfibo2_pyzx = zxfibo(2)  # PyZX\nzxfibo2_ibm_circ = pyzx_to_qiskit(zxfibo2_pyzx)  # Qiskit\n\n\n\n\n\n\n\n\n\n\n\n(a) PyZX\n\n\n\n\n\n\n\n\n\n\n\n(b) Qiskit\n\n\n\n\n\n\n\nFigure¬†1: ZXFibo for n=2 in its PyZX and Qiskit circuit representation.\n\n\n\nUsing the Qiskit API, we can then run ZXFibo using an IBM backend. To not spend any money, I will be running the algorithm on a non-noisy simulator where we can get ideal counts (suppressing probability 0 events) and on a noisy simulator. For the noisy simulator, I will be using the the FakeAthens backend, which is a 5 qubit fake backend that mimics the IBM Athens device.\n\ntry:\n    IBMQ.load_account()\n    provider = IBMQ.get_provider(hub=\"ibm-q\", group=\"open\", project=\"main\")\n    backend = provider.get_backend('ibmq_qasm_simulator')\nexcept:\n    print(\"Error:\", sys.exc_info()[1])\n    print(\"Setting backend to qasm_simulator\")\n    backend = FakeAthens()\n\nWe then run the ZXFibo algorithm for 1000 shots.\n\ndef run(\n    circ: qiskit.QuantumCircuit, backend: qiskit.providers.Backend, shots: int\n) -&gt; dict[str, int]:\n    job = execute(circ, backend, shots=shots)\n    result = job.result()\n    counts = result.get_counts()\n    return counts\n\ncounts = run(zxfibo2_ibm_circ, backend=backend, shots=1000)\nqiskit.visualization.plot_histogram(counts)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Ideal counts\n\n\n\n\n\n\n\n\n\n\n\n(b) Counts on a noisy simulator\n\n\n\n\n\n\n\nFigure¬†2: Simulation results for ZXFibo with n=2 using the IBM backend with 1000 shots.\n\n\n\nFrom the simulation results for n=2, we can see that the algorithm works as expected. In fact, it works too well. On the non-noisy simulator, the histogram depicts exactly the probabilities of 0.25, 0.25, 0.5 for the pairs (0, 0), (0, 1) and (1, 0) respectively. On the noisy simulator otoh, we attain a similar distribution but with ~0.5% noise in the (1, 1) measurement outcome which is tiny relative to the minimum probability for the measurement outcomes with non-consecutive ones of 25%. Setting a 5% threshold in post-processing discards the 0.5% noise and gives us the correct distribution and yields B^2. We then obtain F_2 as |B^2|.\nWe repeat the experiment by running 1000 shots of the ZXFibo algorithm but now with n=3.\n\n\n\n\n\n\n\n\n\n\n\n(a) Ideal counts\n\n\n\n\n\n\n\n\n\n\n\n(b) Counts on a noisy simulator\n\n\n\n\n\n\n\nFigure¬†3: Simulation results for ZXFibo with n=3 using the IBM backend with 1000 shots.\n\n\n\nWe see again that the ZXFibo algorithm works extremely well! The noisy measurement outcomes (i.e.¬†with consecutive ones) accounts for only about 1% of the total probabilities with a single sequence attaining a maximum of only 0.7%. This number is significantly tiny compared to the minimum probability for elements in B^3 of 12.5%. We can again set a 5% threshold in post-processing to get the correct probability distribution and obtain F_3.\nLet‚Äôs now fire 1000 shots of ZXFibo with n=5 to compute the Fibonacci number F_5.\n\n\n\n\n\n\n\n\n\n\n\n(a) Ideal counts\n\n\n\n\n\n\n\n\n\n\n\n(b) Counts on a noisy simulator\n\n\n\n\n\n\n\nFigure¬†4: Simulation results for ZXFibo with n=5 using the IBM backend with 1000 shots.\n\n\n\nAgain, ZXFibo works really well where the noisy measurement outcomes attains less than 1% in probability on average. But we can now start to see an impending doom‚Ä¶ the minimum probability for elements in B^5 is now 3.9%. This is still significantly larger than the maximum attained by the noisy measurement outcome of 0.7% but we can no longer set a 5% threshold in post-processing. Rather, we need to choose a safer threshold, say, at about 2.5% to discard the noisy outcomes and obtain F_5 with confidence. This phenomenon can seem problematic as we increase n so let‚Äôs discuss a bit more about it.\n\nAn impending doom\nBecause this is a heuristic approach, we have no reason to conclude that the maximum attained by the noisy measurement outcomes will exceed beyond 1% as we have seen this is not the case even for increasing n = 2, 3, 5. The only way to verify this is to run more experiments with higher number of qubits. However, the doom pattern that we can clearly see is that as n increases, the minimum probability for elements in B^n decreases. This means that the threshold for discarding the noisy measurement outcomes will have to be set lower and lower, and might eventually reach a point where the threshold is lower than the maximum attained by the noisy measurement outcomes. What is this breaking point though?\nFix n &gt; 1 and define p_{\\mathrm{min}} be the expected probability for the element B^n with lowest probability (relative to other elements in B^n). Assume an error of \\varepsilon &gt; 0 on p_{\\mathrm{min}}. Suppose the error arising from the noisy measurement outcomes is \\delta \\approx 0. Then a reasonable post-processing probability threshold \\tau for discarding noisy outcomes should satisfy \\delta &lt; \\tau &lt; p_{\\mathrm{min}} - \\varepsilon. The problem is that the Fibonacci sequence F_n behaves like an exponential function, which equivalently means that the number of elements in B^n increases exponentially with n. This implies that p_{\\mathrm{min}} will decrease exponentially fast as n increases! Obviously, if \\delta &lt; p_{\\mathrm{min}} - \\varepsilon, then we can always take the midpoint\n \\tau = \\frac{p_{\\mathrm{min}} - \\varepsilon + \\delta}{2} \nto be the count threshold. However, the impending doom is when p_{\\mathrm{min}} - \\varepsilon \\approx \\delta for some sufficiently large N. In this case, there does not exist a stable count threshold \\tau for any n &gt; N + 1 as for n = N, we have\n\\tau = \\frac{p_{\\mathrm{min}} - \\varepsilon + \\delta}{2} \\approx \\frac{2 \\delta}{2} = \\delta.\nSo if we are serious in counting large Fibonacci numbers, we ought to think of a better algorithm and this opens room for further research. For our purpose, however, we just want a benchmark for running Clifford+T hardware. This heuristic is excellent in doing exactly that, especially as per our discussion, for benchmarking how noisy a quantum computer is by looking at the noisy measurement outcomes. In fact, one can use the probability threshold \\tau above as a metric to measure the noise levels."
  },
  {
    "objectID": "posts/2021-04-05-newton-method/index.html",
    "href": "posts/2021-04-05-newton-method/index.html",
    "title": "Root-hunting algorithm: Newton‚Äôs method",
    "section": "",
    "text": "Problem: Given a real-valued function f(x) in one real variable, what are the values x_0 \\in \\mathbb{R} such that f(x_0) = 0?\nIf the function f(x) is linear, then the problem is trivial. Explicitly, if f(x) = ax + b for some a, b \\in \\mathbb{R}, then x_0 = -b/a gives a solution as long as a \\neq 0. However, when the function is nonlinear, the problem can get complicated very fast. For example, try solving when the function is f(x) = \\sin(e^{x}) + \\cos(\\log x).\n\n\nNewton‚Äôs idea (an overview)\nOne way of solving this problem is to linearize the function f(x) around a certain point x_0 of our choice so that we can easily solve the resulting linear equation. Say we get x_1 as a solution, then we repeat linearizing f(x) around x_1; so on and so forth. The initial point x_0 is chosen such that it is close to our hoped solution, say, x^*. The idea is that if x_0 is suitably chosen, then the solutions x_1, x_2, x_3, \\ldots to each linear approximation of f(x) approximates x^* better and better, and in the limit converges to x^*. This whole process is known as the Newton‚Äôs method.\nA nice picture of the Newton‚Äôs method can be seen in Figure¬†1. Here, Newton‚Äôs method is applied to the function f(x) = x^2 over n = 10 iterations, starting at x_0 = 1. We see from Figure¬†1 that the x_i values converges to x^* = 0 which is expected since x^2 = 0 if and only if x = 0.\n\n\n\nNewton‚Äôs idea (the algebra)\nLet us make our discussion above more precise. Linearizing f(x) around x_0 simply means Taylor expanding f around x_0 and neglecting \\mathcal{O}(h^2) terms. Of course‚Ä¶ this is assuming that we can actually perform Taylor expansion in the first place. With that disclaimer out of the way, the Taylor expansion of f around x_0 yields\nf(x) = f(x_0) + f'(x_0) (x - x_0) + \\mathcal{O}(h^2) \\approx f(x_0) + f'(x_0) (x - x_0). \nSo if we neglect \\mathcal{O}(h^2) terms, we get the linear equation\nf(x) = f(x_0) + f'(x_0) (x - x_0).\nSo a solution x_1 that satisfy f(x_1) = 0 is given by\nx_1 = x_0 - \\frac{f(x_0)}{f'(x_0)}\nWe then repeat the process by linearizing f around x_1. In this case we have\nf(x) = f(x_1) + f'(x_1) (x - x_1) \\implies x_2 = x_1 - \\frac{f(x_1)}{f'(x_1)}, \nwith x_2 being a solution. Doing this iteratively yields a general formula\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)},\nknown as Newton‚Äôs formula. Here is the Newton‚Äôs method in one statement.\n\n\nTheorem 1 (Newton‚Äôs method) Let x^* \\in \\mathbb{R} be a solution to f(x) = 0. If x_n is an approximation of x^* and f'(x_n) \\neq 0, then the next approximation to x^* is given by x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}, with initial condition, a suitably chosen x_0 \\in \\mathbb{R}.\n\n\n\n\nCode implementation\nAn iterative implementation of the Newton‚Äôs method in Python is given below:\n\ndef iterative_newton(f, df, x0, n):\n    \"\"\"Solves f(x) = 0 using the Newton's method.\n\n    Args:\n        f: A callable, the function f(x) of interest.\n        df: A callable, the derivative of f(x).\n        x0: Initial good point to start linearizing.\n        n (Optional): Number of recursion steps to make.\n    \"\"\"\n    xs = [x0] # Sequence of xn.\n\n    # Get latest x value in sequence and\n    # apply the Newton recurrence formula.\n    for _ in range(n):\n        last = xs[-1]\n        res = last - f(last)/df(last)\n        xs.append(res)\n\n    return xs\n\nUsing the same parameters as above, we can also implement a one-liner recursive implementation:\n\ndef recursive_newton(f, df, x0, n):\n    return x0 if n &lt;= 0 else recursive_newton(f, df, x0 - f(x0)/df(x0), n-1)\n\nObserve that both algorithms have \\mathcal{O}(n) space complexity where n is the number of iterations or depth of the recursion. The time complexity for the iterative implementation is also \\mathcal{O}(n), but for the recursive implementation, it is a bit tricky to compute (so we leave it as an exercise!).\nNote that there is a small caveat to the Newton‚Äôs method which we have implicitly highlight in this post, can you spot it?\n\n\nExample usage: finding root of f(x) = x^2\n\n\nLibrary imports\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nWe first need a helper function to differentiate a function using finite difference approximation.\n\ndef finite_diff(f):\n    \"\"\" Returns the derivative of f(x) based on the\n    finite difference approximation.\n    \"\"\"\n    h = 10**(-8)\n    def df(x):\n        return (f(x+h)-f(x-h)) / (2*h)\n    return df\n\nWe then define the function f(x) = x^2, compute its derivative and apply Newton‚Äôs method over n = 10 iterations, starting at x_0 = 1.\n\nf = lambda x: x**2\ndf = finite_diff(f)  # Differentiate f(x).\nres = iterative_newton(f, df, 1, 10)\nres = np.array(res)  # To utilize numpy broadcasting later.\n\nFinally, we plot the function.\n\n\nPlotting code\nplt.style.use('bmh')\n\n# Bounds on the x-axis.\nlo = -0.1\nhi = 1.1\nmesh = abs(hi) + abs(lo)\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Points of the function f(x).\nxs = np.arange(start=lo, stop=hi, step=0.01)\nys = f(xs)\n\ndef tangent_line(f, x0, a, b):\n    \"\"\" Generates the tangent line to f(x) at x0 over\n    the interval [a, b]. Helps visualize the Newton's method.\n    \"\"\"\n    df = finite_diff(f)\n    x = np.linspace(a, b, 300)\n    ytan = (x - x0)*df(x0) + f(x0)\n\n    return x, ytan\n\n# Tangent lines to f(x) at the approximations.\nxtan0, ytan0 = tangent_line(f, res[0], 0.35*mesh, hi)\nxtan1, ytan1 = tangent_line(f, res[1], 0.1*mesh, hi)\nxtan2, ytan2 = tangent_line(f, res[2], lo, 0.7*mesh)\n\nax.plot(xs, ys, label=\"$f(x) = x^2$\", linewidth=3)\nax.plot(xtan0, ytan0, label=\"Linearization 1\", alpha=0.8)\nax.plot(xtan1, ytan1, label=\"Linearization 2\", alpha=0.8)\nax.plot(xtan2, ytan2, label=\"Linearization 3\", alpha=0.8)\nax.plot(res, f(res), color='darkmagenta',\n        label=\"Newton's method\\napproximations\",\n        marker='o', linestyle='None', markersize=6)\n\n# Labels for occurring approximations.\nfor i in range(0, 4):\n    ax.plot(res[i], 0, marker='+', color='k')\n    ax.vlines(res[i], ymin=0, ymax=f(res[i]),\n              linestyles='dotted', color='k', alpha=0.3)\n    plt.annotate(f\"$x_{i}$\",\n                 (res[i], 0),\n                 textcoords=\"offset points\",\n                 xytext=(0, -20),\n                 ha='center',\n                 fontsize=16)\n\n# Grid and xy-axis.\nax.grid(True, which='both')\nax.axvline(x = 0, color='k')\nax.axhline(y = 0, color='k')\n\n# Labels and legend.\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.set_title(\"Newton's method applied to $f(x) = x^2$\")\nplt.legend(fontsize=12, loc=9)\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure¬†1: Newton‚Äôs method applied to f(x) = x^2, starting at x_0 = 1."
  },
  {
    "objectID": "posts/2023-03-05-clash-is-prime/index.html",
    "href": "posts/2023-03-05-clash-is-prime/index.html",
    "title": "Clash Series: Checking Number is Prime",
    "section": "",
    "text": "This is the first of hopefully many more posts on Clash of Code tricks I learn along the way. I call this the Clash Series and in today‚Äôs series, we look at how to write an efficient script to check for prime numbers, and how to write it fast python for those fastest mode clashes.\nEquivalently, we say p is prime if p &gt; 1 and whenever it decomposes into p = ab, then either a=1, b=p or a=p, b=1. Thus, if p is not prime, then there is a decomposition of p into a product of positive integers a, b that are not necessarily 1 or p; hence, the name composite.\nThe first few prime numbers are 2, 3, 5, 7, 11 and so on, while the first few composite numbers are 1, 4, 6, 8, 9 and so on.\nNow here is what we are interested in."
  },
  {
    "objectID": "posts/2023-03-05-clash-is-prime/index.html#the-problem",
    "href": "posts/2023-03-05-clash-is-prime/index.html#the-problem",
    "title": "Clash Series: Checking Number is Prime",
    "section": "The problem",
    "text": "The problem\n\nproblem statement\n\nGiven an integer n \\in \\mathbb{Z}, how to enumerate all prime numbers less than n?\n\n\nA naive enumeration algorithm can be achieved in the following way: For any given integer n,\n\nIf n &lt; 2, then n cannot be prime.\nIf n = 2, then n is prime.\nLoop over all integers k \\in [3, n). If there exists k such that k \\equiv 0 \\bmod n, then n is not prime. Otherwise n is prime.\n\nA python code for this naive implementation is as follows.\n\ndef is_prime_naive(n: int) -&gt; bool:\n    # 1 and any negative integer are not prime.\n    if n &lt; 2:\n        return False\n    # 2 is prime.\n    if n == 2:\n        return True\n    for k in range(2, n):\n        # If n is divisible by k for any k &lt; n, n is not prime.\n        if n % k == 0:\n            return False\n    return True\n\nThe time complexity for this algorithm is \\mathcal{O}(n) where n is the given integer. This is already good in most cases, but can we do better?\nWell any integer n &gt; 2 is always divisible by 2 if it is even, and therefore cannot be prime. So we can add a step to check if n is even or not before doing the looping step. As a result, our algorithm running time is cut in half as we now only have to loop over only odd numbers less than n.\n\ndef is_prime_better(n: int) -&gt; bool:\n    # 1 and any negative integer are not prime.\n    if n &lt; 2:\n        return False\n    # 2 is prime.\n    if n == 2:\n        return True\n    # NEW: If n is even and n is not 2, then it is not prime.\n    if n % 2 == 0:\n        return False\n    for k in range(3, n, 2):\n        # NEW: If n is divisible by odd k for any k &lt; n, n is not prime.\n        if n % k == 0:\n            return False\n    return True\n\nThe problem, however, is that the theoretical time complexity of this algorithm is still \\mathcal{O}(n/2) = \\mathcal{O}(n). So good for small n but still problematic for super large n."
  },
  {
    "objectID": "posts/2023-03-05-clash-is-prime/index.html#efficient-algorithm-sqrt-trick",
    "href": "posts/2023-03-05-clash-is-prime/index.html#efficient-algorithm-sqrt-trick",
    "title": "Clash Series: Checking Number is Prime",
    "section": "Efficient algorithm (sqrt trick)",
    "text": "Efficient algorithm (sqrt trick)\nSo what can we do to make this code faster? Enter‚Ä¶ the square root (sqrt) trick.\nFirst, without loss of generality, let‚Äôs assume that n is a positive integer since if n &lt; 2, then it‚Äôs taken care by the n &lt; 2 check. We now make the following claim.\n\nLemma 1 (Sqrt Decomposition) Let n &gt; 1 be a positive integer. If n = ab is a composite integer such that 0 &lt; a \\leqslant b, then a \\leqslant \\sqrt{n} \\leqslant b.\n\n\nProof. First observe that n = ab is a perfect square if and only if a = b = \\sqrt{n}, in which case we are done.\nSo suppose n = ab is not a perfect square. Then a and b cannot be \\sqrt{n} and moreover a &lt; b. We now claim that a &lt; \\sqrt{n} &lt; b. Suppose a &lt; \\sqrt{n} but also b &lt; \\sqrt{n}, then ab &lt; n which is a contradiction. Similarly, if both a &gt; \\sqrt{n} and b &gt; \\sqrt{n}, then ab &gt; n, also a contradiction. Thus, since a &lt; b, it has to be that a &lt; \\sqrt{n} &lt; b. \\blacksquare\n\nSo what‚Äôs the point of Lemma¬†1? Well the main takeaway is the following: if the number n is composite, then we will at least find one of its divisors before or equal its integer square root \\lfloor \\sqrt{n} \\rfloor.\n\nTheorem 1 Let n be a composite positive integer. Then there exists a prime divisor p of n such that p \\leqslant \\lfloor \\sqrt{n} \\rfloor.\n\n\nProof. By Lemma Lemma¬†1, we know that if n = kb is a composite integer with 0 &lt; k \\leqslant b, then k \\leqslant \\sqrt{n}, with equality iff n is a perfect square. Equivalently, this means that k \\leqslant \\lfloor \\sqrt{n} \\rfloor. If k is prime, then we are done. Otherwise, there exists a prime p that divides k (hence, divides n) that would also satisfy p \\leqslant \\lfloor \\sqrt{n} \\rfloor as desired. \\blacksquare\n\n\nNote: for a linear traversal check (like we are doing, starting from 3, 4, 5, ‚Ä¶), we know that we will encounter any prime divisor p of any composite divisor k of n first. So the last part of the proof is unnecessary for our need, but we put it there for completeness.\n\nSo the idea of using sqrt decomposition speeds up our algorithm tremendously, especially for large n. In fact, even for small n like n=1080, its integer square root is 32 which is already two order of magnitudes lower.\nWe now add the sqrt trick to our python implementation.\n\ndef is_prime_sqrt_trick(n: int) -&gt; bool:\n    # 1 and any negative integer are not prime.\n    if n &lt; 2:\n        return False\n    # 2 is prime.\n    if n == 2:\n        return True\n    # If n is even and n is not 2, then it is not prime.\n    if n % 2 == 0:\n        return False\n    # NEW: loop until int(sqrt(n)) + 1.\n    # The + 1 is to handle if n is perfect square.\n    for k in range(3, int(n**.5)+1, 2):\n        # If n is divisible by odd k for any k &lt; n, n is not prime.\n        if n % k == 0:\n            return False\n    return True\n\nThe sqrt trick improves time complexity from \\mathcal{O}(n) to \\mathcal{O}(\\sqrt{n}) which is massive! To give you an idea of this speedup, we will run the naive and sqrt algorithms to check if n = 2{,}147{,}462{,}143 is prime. Note that this is a prime number on the order of 2^{31}.\n\nThe sqrt trick improves time complexity from \\mathcal{O}(n) to \\mathcal{O}(\\sqrt{n}) which is massive!\n\n\n\nspeedup comparison ‚ö°Ô∏è\n\nimport time\n\nn = 2_147_462_143\n\nfor f in [is_prime_naive, is_prime_sqrt_trick]:\n    start = time.time()\n    f(n)\n    print(f\"Took total of {(time.time()-start):.10f} seconds using {f.__name__}\")\n\nTook total of 118.3165051937 seconds using is_prime_naive\nTook total of 0.0010521412 seconds using is_prime_sqrt_trick"
  },
  {
    "objectID": "posts/2023-03-05-clash-is-prime/index.html#efficient-writing",
    "href": "posts/2023-03-05-clash-is-prime/index.html#efficient-writing",
    "title": "Clash Series: Checking Number is Prime",
    "section": "Efficient writing",
    "text": "Efficient writing\nSo the impementation is super efficient \\mathcal{O}(\\sqrt{n}), but how do we make writing the code efficient for something like Clash of Code?\nWell first note that when writing in a clash, you don‚Äôt care about the 80 char PEP format or readability. So it‚Äôs finally time to write one-liner 100 chars fugly code.\nThe trick I use is to use all to replace the for-loop and replace the False checks with True statement by ‚Äúbundling‚Äù their evaluation using and. This gives the following one-liner.\n\ndef is_prime_sqrt_short(n: int) -&gt; bool:\n    return n == 2 or (n &gt; 2 and n % 2 != 0 and all(n % k != 0 for k in range(3, int(n**.5)+1, 2)))\n\nIn fact, since the modulo operator % in python returns a positive integer, we can save writing one character for each != by writing &gt; instead.\n\ndef is_prime_sqrt_super_short(n: int) -&gt; bool:\n    return n == 2 or (n &gt; 2 and n % 2 &gt; 0 and all(n % k &gt; 0 for k in range(3, int(n**.5)+1, 2)))"
  },
  {
    "objectID": "posts/2024-08-13-ensembling-bagging-rf/index.html",
    "href": "posts/2024-08-13-ensembling-bagging-rf/index.html",
    "title": "Quickest intro to random forest",
    "section": "",
    "text": "As its name suggests, ensembling is quite literally ensembling several machine learning models to create a meta-model that (in theory) is better than any of the individual models. The meta-model is built typically via an averaging procedure. The idea has a natural intuition behind it: if you consider n iid model outputs X_1, \\ldots, X_n with variance \\mathrm{Var}(X_i) = \\sigma^2, then the sample mean variance given by \\mathrm{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} converges to 0 as n \\to \\infty.\nIn reality, however, you don‚Äôt really get independence so the X_i are at most only identically distributed. This changes the math a bit, so let‚Äôs derive the sample mean variance again:\n\n\\begin{align*}\n\\mathrm{Var}(\\bar{X})\n&= \\frac{1}{n^2} \\mathrm{Var}(X_i) + \\frac{1}{n^2} \\sum_{i, j} \\mathrm{Cov}(X_i, X_j) \\\\\n&= \\frac{\\sigma^2}{n} + \\frac{n-1}{n} \\rho \\sigma^2 \\\\\n&= \\rho \\sigma^2 + \\frac{1 - \\rho}{n}\\sigma^2,\n\\end{align*}\n\nwhere \\rho is the average correlation across the X_i. To create a meta-model now, we want two things to happen:\n\nWe want to consider as many different models as possible so that n \\to \\infty and hence (1-\\rho)\\sigma^2/n \\to 0.\nWe also want the models to be as decorrelated as possible so that \\rho \\to 0 and hence \\rho \\sigma^2 \\to 0 and we are back in the iid case.\n\nThis gives rise to several different ways of ensembling machine learning models. One that is quite popular is called bootstrap aggregation or simply bagging and it is a very simple procedure."
  },
  {
    "objectID": "posts/2024-08-13-ensembling-bagging-rf/index.html#why-ensemble",
    "href": "posts/2024-08-13-ensembling-bagging-rf/index.html#why-ensemble",
    "title": "Quickest intro to random forest",
    "section": "",
    "text": "As its name suggests, ensembling is quite literally ensembling several machine learning models to create a meta-model that (in theory) is better than any of the individual models. The meta-model is built typically via an averaging procedure. The idea has a natural intuition behind it: if you consider n iid model outputs X_1, \\ldots, X_n with variance \\mathrm{Var}(X_i) = \\sigma^2, then the sample mean variance given by \\mathrm{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} converges to 0 as n \\to \\infty.\nIn reality, however, you don‚Äôt really get independence so the X_i are at most only identically distributed. This changes the math a bit, so let‚Äôs derive the sample mean variance again:\n\n\\begin{align*}\n\\mathrm{Var}(\\bar{X})\n&= \\frac{1}{n^2} \\mathrm{Var}(X_i) + \\frac{1}{n^2} \\sum_{i, j} \\mathrm{Cov}(X_i, X_j) \\\\\n&= \\frac{\\sigma^2}{n} + \\frac{n-1}{n} \\rho \\sigma^2 \\\\\n&= \\rho \\sigma^2 + \\frac{1 - \\rho}{n}\\sigma^2,\n\\end{align*}\n\nwhere \\rho is the average correlation across the X_i. To create a meta-model now, we want two things to happen:\n\nWe want to consider as many different models as possible so that n \\to \\infty and hence (1-\\rho)\\sigma^2/n \\to 0.\nWe also want the models to be as decorrelated as possible so that \\rho \\to 0 and hence \\rho \\sigma^2 \\to 0 and we are back in the iid case.\n\nThis gives rise to several different ways of ensembling machine learning models. One that is quite popular is called bootstrap aggregation or simply bagging and it is a very simple procedure."
  },
  {
    "objectID": "posts/2024-08-13-ensembling-bagging-rf/index.html#bagging-and-its-bias-variance-tradeoff",
    "href": "posts/2024-08-13-ensembling-bagging-rf/index.html#bagging-and-its-bias-variance-tradeoff",
    "title": "Quickest intro to random forest",
    "section": "Bagging and its bias-variance tradeoff",
    "text": "Bagging and its bias-variance tradeoff\nLet \\mathcal{P} be the true population, and suppose we have a training set \\mathcal{S} sampled from \\mathcal{P}. Then, we can create n bootstrap samples Z_1, \\ldots, Z_n by sampling from \\mathcal{S} with replacement. This is the bootstrap step. We then train n different models G_1, \\ldots, G_n on these bootstrap samples for each i. Further, we create a meta-model\nG(i) = \\frac{1}{n} \\sum_{i=1}^n G_i(x)\nthat essentially averages the predictions of the G_i. This is the aggregation step.\nLet‚Äôs consider the bias-variance tradeoff for the bagging procedure. Generally, bootstrapping decreases the average correlation \\rho as we perform random subsampling with replacement without accounting for specific features in the dataset. As a consequence, the correlation term \\rho \\sigma^2 decreases. Further, the variance term (1-\\rho)\\sigma^2/n decreases as we increase n. However, as a tradeoff, we have increased the bias since we are training on bootstrap samples Z_i \\subset \\mathcal{S}. This is a classic no free lunch scenario in machine learning where as the variance decreases, you risk increasing the bias.\nHaving said that, the decision tree is a perfect model to be used in constructing a meta-model via bagging. This is because the decision tree is a high variance, low bias model so the net effect of performing bagging is, in some sense, mitigated.\nWe can further add an additional step to further decorrelate the decision tree outputs. Rather than considering the entire feature space, we can consider only a fraction of the total features at each split. As a consequence, the correlation term \\rho \\sigma^2 decreases even further! This meta-model that arises from performing bagging using decision trees with this additional procedure is called a random forest.\nSo a random forest is essentially:\n\n\\mathrm{RandomForest} = \\mathrm{Bagging}(\\mathrm{DecisionTree}(\\mathrm{RandomFeatureSubspace}))."
  },
  {
    "objectID": "posts/2023-03-06-ls-aws-in-python/index.html",
    "href": "posts/2023-03-06-ls-aws-in-python/index.html",
    "title": "How to do aws s3 ls s3://bucket/ using boto3 in python?",
    "section": "",
    "text": "Today, we look at how can we perform the following terminal command in python."
  },
  {
    "objectID": "posts/2023-03-06-ls-aws-in-python/index.html#why-do-we-even-care",
    "href": "posts/2023-03-06-ls-aws-in-python/index.html#why-do-we-even-care",
    "title": "How to do aws s3 ls s3://bucket/ using boto3 in python?",
    "section": "Why do we even care?",
    "text": "Why do we even care?\nA lot of times, you just want to list all the existing subobjects in a given object without getting its content. A typical use case is to list all existing objects in the bucket, where here, the bucket is viewed as an object ‚Äì the root object. This list action can be achieved using the simple aws s3 ls command in the terminal.\nBut what if we want to do it natively as part of a module in python? For example, if we want to trigger a callback on the server whenever a new subobject is found in our bucket. A fast way is to just perform an equivalent aws s3 ls in our python module, and this is our goal today.\nTo ensure clarity, let‚Äôs kick off with the definition of a path, a bucket and an object prefix.\n\ndefinition\n\nA path is a string that consists of an S3 tag, a bucket and an object prefix. For example, s3://bucket/object/subobject/... is a generic path where s3:// is the S3 tag, bucket is the bucket and object/subobject/... is the object prefix. Note the position of / carefully."
  },
  {
    "objectID": "posts/2023-03-06-ls-aws-in-python/index.html#aws-s3-ls-in-python",
    "href": "posts/2023-03-06-ls-aws-in-python/index.html#aws-s3-ls-in-python",
    "title": "How to do aws s3 ls s3://bucket/ using boto3 in python?",
    "section": "aws s3 ls in python",
    "text": "aws s3 ls in python\nI assume that you‚Äôve done the standard AWS credentials step, storing it at ~/.aws/credentials for example. We can then initialize an S3 client in Python using boto3.session.Session, I hope this step is familiar to you.\nimport boto3\n\nsession = boto3.session.Session()\nclient = session.client(\"s3\")\nNow that we have our S3 client, define our bucket and object prefix of interest.\nbucket = \"bucket_name\"\nobj_prefix = \"obj_in_bucket/\"\nThen we can simply list all the existing subobjects of our given object prefix using the following function:\ndef aws_s3_ls(bucket: str, obj_prefix: str):\n    params = dict(Bucket=bucket, Prefix=obj_prefix, Delimiter=\"/\")\n\n    paginator = client.get_paginator(\"list_objects_v2\")\n    for page in paginator.paginate(**params):\n        for obj in page.get(\"CommonPrefix\", []):\n            print(\"PRE\", obj[\"Key\"])\n\naws_s3_ls(bucket, obj_prefix)\nPRE subobj_1/\nPRE subobj_2/\nPRE subobj_3/\n...\nAnd that‚Äôs it! That was a short one and I hope to cover more AWS things in the future."
  },
  {
    "objectID": "posts/2021-04-07-tcolorbox/index.html",
    "href": "posts/2021-04-07-tcolorbox/index.html",
    "title": "Making pastel-colored boxes using tcolorbox in LaTeX",
    "section": "",
    "text": "One of the many questions I get when people see my \\LaTeX-ed math notes is how do you create these nice pastel-colored boxes?\n \n\nTwo examples of pastel-colored boxes from my math notes\n\n\nI feel like this is a very relevant and important question, because I asked the exact same thing when I was new to \\LaTeX.\n\nSimple box using fbox and minipage\nMy first exposure to \\LaTeX box-like environments was my mentor Ghaleo‚Äôs genius tutorial notes. He used them for two main reasons:\n\nto highlight important theorems, lemmas, etc;\nan empty space for students to follow along and fill in the blanks live in class.\n\nI tried to reproduce his box environment when I was writing my very first math notes on \\LaTeX ‚Äì my Linear Algebra & Geometry II notes.\n\n\nA snippet of my Linear Algebra & Geometry II notes\n\nIt was achievable using the fbox environment alone, but for it to generalize well, I have to throw in a minipage usage as well. The code implementation is quite simple and requires no package imports. Just use the following code directly in your document:\n% Simple box environment.\n\\fbox{ %\n\\begin{minipage}[t]{0.9\\textwidth}\n    % Your text here.\n\\end{minipage}\n}\nTo make the box look cleaner, use the center environment as well. Here is a concrete example of using this box. The code:\n\\begin{document}\n\n\\begin{center}\n\\fbox{ %\n\\begin{minipage}[t]{0.9\\textwidth}\n    This is a plain small box.\n\\end{minipage}\n}\n\\end{center}\n\n\\end{document}\nwould yield the box:\n\nNow the problem with this simple fbox is that‚Ä¶ it‚Äôs just plain black and white. I want something more vibrant and colourful, so I decided to start learning the tcolorbox package.\n\n\n\nTransition to tcolorbox\nAs usual, the best way to learn is to straight dive in and do. After (very) little reading on the package‚Äôs documentation, I started to recreate pretty boxes that other people have made from scratch. These boxes are usually from notes I found online like:\n\nEvan Chen‚Äôs The Napkin project;\nTony Zhang‚Äôs notes snippets from his Quora post;\nor even the tcolorbox documentation itself.\n\nWith my then minimal knowledge, I started writing my Real Analysis notes. I was quite happy with the end product but the overall design felt a bit odd (as you can see in the figure below). Nevertheless, my initial goal was to just make prettier boxes and I think I‚Äôve achieved just that.\n\n\nA snippet of my Real Analysis notes\n\nTo reproduce the (proof) box above with a Cerulean colour, use the following code in your document‚Äôs preamble:\n% In preamble.\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage[many]{tcolorbox}\n\n\\newtcolorbox{myAwesomeBox}{\n    enhanced,\n    sharp corners,\n    breakable,  % Allows page break.\n    borderline west={2pt}{0pt}{Cerulean},\n    colback=Cerulean!10,  % Background color.\n    colframe=Cerulean!10  % Frame (border) color.\n}\nTo see this box in action, we instantiate this environment in our document:\n\\begin{document}\n\n\\begin{myAwesomeBox}\n    This nice blue pastel box!\n\\end{myAwesomeBox}\n\n\\end{document}\nThis code should then yield:\n\nI want to note two things regarding the imports:\n\nThe dvipsnames option for xcolor is simply a choice of the set of colors I want from xcolor. It does affect the name of colors you can pass as arguments, for example, here I used Cerulean. For a full set of possible colors in xcolor, see here.\nThe many option for tcolorbox loads additional libraries which allows us to use more features from tcolorbox. In particular for our use case, we want to be able to use enhanced. See the documentation for other options.\n\nHere are some tweaks that you might want to consider:\n\nIf you want to add a nice smooth border-like effect, do this: instead of using colframe=Cerulean!10, remove that line and put boxrule=0pt instead. In general, boxrule adjusts the border stroke.\nIf you want to remove padding inside the box, add boxsep=0pt. In general, boxsep controls the inside padding.\n\nThere are many more parameters that you can control and these can be found in the tcolorbox documentation.\nNowadays, I write my notes using the NotesTex package which coincidentally uses tcolorbox with a similar setting as mine. I guess this is one of the reasons why it was a no brainer for me to use it in the first place. The nice thing about the package is that it provides a complete framework to write notes in \\LaTeX. In particular, you don‚Äôt have to reinvent the wheel for everything (e.g.¬†theorem environment, sidenotes). And for features that you feel are missing, you can simply add it on your own with ease. I‚Äôve added plenty of features already and they integrate quite well. I‚Äôd highly recommend checking NotesTex out!"
  },
  {
    "objectID": "posts/2024-04-22-asbf-primer-01/index.html",
    "href": "posts/2024-04-22-asbf-primer-01/index.html",
    "title": "A mathematical take on when to take a loan such as ASB Financing",
    "section": "",
    "text": "Disclaimer: Nothing written here is investment advice."
  },
  {
    "objectID": "posts/2024-04-22-asbf-primer-01/index.html#measuring-poor-financing-choices-with-curves",
    "href": "posts/2024-04-22-asbf-primer-01/index.html#measuring-poor-financing-choices-with-curves",
    "title": "A mathematical take on when to take a loan such as ASB Financing",
    "section": "Measuring poor financing choices with curves",
    "text": "Measuring poor financing choices with curves\nRecall that returns is a function of capital, but also assumes a fixed dividend and interest rate r. By relaxing the interest rate r assumption in \\tilde{f}(C; d, r), we see that r defines the family of financed curves \\tilde{f}(C, r; d). If we further relax the fixed dividend rate d assumption, we obtain a wider family of curves for both f(C, d, r) and \\tilde{f}(C, d, r). So how can we measure which financed curves are worse? One metric that I think is useful is the area enclosed between f and \\tilde{f}, bounded by the minimum and maximum of f. Where f, \\tilde{f} are linear functions in C, this area looks like a rhombus and the goal is to make this rhombus as small as possible. Let C_0 be the minimum amount of invested capital where 0 \\leqslant C_0 \\leqslant C_1; this should be the value that minimizes f. Then using very basic geometry, you can obtain this metric as the following quantity:\n\n\\begin{align*}\n\\mathrm{Loss}(f, \\tilde{f}) &= \\int_{[C_0, C_1]} \\left(f(C) - \\min_{C} f(C)\\right) \\mathrm{d}C + \\int_{[C_1, C_2]} \\left(\\max_{C} f(C) - \\tilde{f}(C)\\right) \\mathrm{d}C \\\\\n&= \\int_{[C_0, C_1]} \\left(f(C) - f(C_0)\\right) \\mathrm{d}C + \\int_{[C_1, C_2]} \\left(f(C_1) - \\tilde{f}(C)\\right) \\mathrm{d}C.\n\\end{align*}\n\nSo a good financing option ‚Äì where interest rate is minimized ‚Äì should be where the loss metric above is minimized. It can be rather tedious to compute this, especially when the return models f and \\tilde{f} gets bloated with other discount rates to make the model more accurate. Thankfully, however, there is an equivalence between this metric and the parity difference under certain conditions suggesting that it can be sufficient to look at the parity difference.\nIf one examines the loss function above, one observe that the first part is entirely defined by f. This quantity acts only as a bias term in the loss computation. Rather, the second quantity is what we should put our focus on. In the second integral, note that f(C_1) is fixed when f is fixed. But both f and \\tilde{f} is dependent on the dividend rate d. So suppose we fix a dividend rate, we can then minimize the loss on \\tilde{f} just over the space of possible interest rates and functional forms. Let‚Äôs make this even simpler and just focus on linear forms. In this case, it‚Äôs just a matter of minimizing interest rates which is equivalent to minimizing the range [C_1, C_2]. And that was exactly the parity difference we defined before!"
  },
  {
    "objectID": "drafts/2024-08-09-cnn-rotation-invariant/index.html",
    "href": "drafts/2024-08-09-cnn-rotation-invariant/index.html",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "",
    "text": "‚ÄúWhy is a convolutional neural network not rotation invariant?‚Äù.\nThis question popped up in an interview recently, and it is surprisingly deeper than I initially thought. For a start, the statement ‚Äúa convolutional neural network is not rotation invariant‚Äù is not entirely true, but only half-true, maybe a quarter-true. So why is this a popular statement being asked in the machine learning domain? I feel like this is mainly due to a poor understanding of the convolutional neural net architecture.\nWhat‚Äôs surprising is how little I have been able to find on the internet about this question. The articles that I have found are unoriginal and poor derivatives of what was written in (Goodfellow, Bengio, and Courville 2016); and like any good mathematics textbook, they do not really do a deep dive into the mathematical reasoning behind the statement ‚Äì which make interpretations written around it even worse. In fact, Goodfellow, Bengio, and Courville (2016) mentions that a convolutional neural net is rotation invariant with the right layers‚Ä¶ so what the heck is going on here?\nToday, I am putting this question to bed with a somewhat acceptable mathematical reasoning. Let‚Äôs get one important thing out of the way first because this might confuse some people. The statement ‚Äúconvolutional net is not rotation invariant‚Äù is somewhat misleading; and this is a consequence of people not understanding the difference betwen a convolutional neural net, a convolutional layer and a convolutional operator. So what is actually ‚Äúconvolution‚Äù in convolutional neural net?"
  },
  {
    "objectID": "drafts/2024-08-09-cnn-rotation-invariant/index.html#what-is-actually-a-convolutional-neural-net",
    "href": "drafts/2024-08-09-cnn-rotation-invariant/index.html#what-is-actually-a-convolutional-neural-net",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "What is actually a convolutional neural net?",
    "text": "What is actually a convolutional neural net?\nA convolutional neural network is simply a neural network where at least one of its layers utilize the convolutional operator rather than a full-blown matrix multiplication (Goodfellow, Bengio, and Courville 2016). This definition is so general that it renders the statement ‚Äúwhy is a convolutional neural network (CNN) not rotation invariant?‚Äù to be false, especially with our breadth of understanding on deep learning today. I will demonstrate why precisely in the rest of this article.\nSo let‚Äôs go down one step in the rabbit hole‚Ä¶ what is a convolution? A convolution * of two complex-valued functions I and K is simply the integral transform\nJ(t) := (I * K)(t) = \\int_{\\mathbb{R}^d} I(\\tau) K(t - \\tau) d\\tau = \\int_{\\mathbb{R}^d} I(t - \\tau) K(t) d\\tau.\nIn computer vision, we are, at the most basic level, concerned with the discrete convolution of real-valued objects (i.e.¬†images) over a finite two-dimensional integer support. Although, this is not exactly true because with modern convolutional neural nets, you actually perform multi-channel convolution which is typically modelled with a four-dimensional kernel tensor instead. Let‚Äôs focus only on the basics though. In the two-dimensional case, the convolution above reduces (and simplifies) to\nJ[i, j] = \\sum_{m, n} I[i- m, j- n] K[m, n],\nwhere I, K are real-valued functions over \\mathbb{Z}^2 and the summation is done over the support of K. Here, I use square brackets instead of parentheses to align with literature on discrete convolution.\nNow, I claim that the convolution operator is not rotation invariant. But before that, let‚Äôs look at something even simpler. I claim that the convolution operator is not even translation invariant!"
  },
  {
    "objectID": "drafts/2024-08-09-cnn-rotation-invariant/index.html#convolution-is-not-translation-invariant",
    "href": "drafts/2024-08-09-cnn-rotation-invariant/index.html#convolution-is-not-translation-invariant",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "Convolution is not translation invariant",
    "text": "Convolution is not translation invariant\nTo prove that convolution is not translation invariant, it suffices to look at a single nonzero shift s in the x-coordinate where we observe that\n\n\\begin{align*}\nJ[i, j]\n&= \\sum_{m, n} I[i-m, j-n] K[m, n] \\\\\n&\\neq \\sum_{m, n} I[i-m+s, j-n] K[m, n] \\\\\n&= J[i + s, j].\n\\end{align*}\n\nObviously, this is a sum of (a lot of) product terms so there are several ways where equality J[i,j] = J[i + s, j] can be achieved; but it is not a guarantee. \\blacksquare\nHere‚Äôs a simple concrete example to see where they are not equal. Define I to be the function [m, n] \\mapsto 1 and let K be defined by\n\n[m, n] \\mapsto\n\\begin{cases}\n1 & \\text{if } m = n \\text{ and } m, n \\neq 0, \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\nover \\{ 0, 1, 2\\} \\times \\{ 0, 1, 2 \\} \\subseteq \\mathbb{Z}^2. Then evaluating J at (i, j) = (0, 1) gives J[i, j] = 0 but J[i+1, j] = 1.\nNow was that surprising? Did you feel lied to all your life that convolutional neural nets are translation invariant? Well, we‚Äôll get to why that statement is commonly made later at the end of this post. For now, let me show you that the convolution operator is not rotation invariant."
  },
  {
    "objectID": "drafts/2024-08-09-cnn-rotation-invariant/index.html#convolution-is-not-rotation-invariant",
    "href": "drafts/2024-08-09-cnn-rotation-invariant/index.html#convolution-is-not-rotation-invariant",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "Convolution is not rotation invariant",
    "text": "Convolution is not rotation invariant\nNow that you‚Äôve got a basic idea on how to disprove convolution being translation invariant, it should be straightforward to see that convolution is not rotation invariant‚Ä¶ at least a sketch proof should be present in your mind. Reasoning it formally, however, takes a bit more effort as we need to do some setup first. For a start, I am going to make things simple by expanding the domain back to \\mathbb{R}^2 because I do not want to talk about rotation matrices in \\mathbb{Z}^2 which is not pretty. As a bonus to doing this, we are now back in the world of vector spaces‚Ä¶ although we can always make an extra effort and start talking about \\mathbb{Z}^2 as a module over itself. Let‚Äôs now start putting the pieces together.\nLet p_{\\mathrm{center}} = (0, 0) \\in \\mathbb{R}^2 be the image center; then define a two-dimensional Cartesian coordinate system centered at p_{\\mathrm{center}} and fix the standard basis. This defines the axes that we will play around to perform rotation. Now that we have that set up, for any vector x \\in \\mathbb{R}^2, we can perform a counterclockwise rotation of \\theta degrees around p_{\\mathrm{center}} by applying the rotation matrix\nR_\\theta = \\begin{pmatrix} \\cos \\theta & -\\sin \\theta \\\\ \\sin \\theta & \\cos \\theta \\end{pmatrix}.\nThen for an image I_0(x): \\mathcal{D} \\subseteq \\mathbb{R}^2 \\to \\mathbb{R}, the corresponding image I_\\theta rotated by \\theta degrees around p_{\\mathrm{center}} is given by the image I_\\theta(y): \\mathcal{D}' \\subseteq \\mathbb{R}^2 \\to \\mathbb{R} where I_\\theta(y) = I_0(x) and y = R_\\theta x (or equivalently, x = R_\\theta^{-1} y).\nNow fix a finite canvas to draw our images on so let \\Omega \\subseteq \\mathbb{R}^2 be a bounded domain such that \\mathcal{D}, \\mathcal{D'} \\subseteq \\Omega. Suppose now that the point q \\in \\mathcal{D} is mapped (bijectively) to q' \\in \\mathcal{D}' under the rotation R_\\theta. Then we can now see that the convolution with rotation is not equal to the convolution without rotation as follows\n\n\\begin{align*}\nJ_\\theta(q') &= \\sum_{p \\in \\Omega} I_{\\theta}(q'-p) K(p) \\\\\n&= \\sum_{p \\in \\Omega} I_0(R_{-\\theta} q' - R_{-\\theta} p) K(p) \\\\\n&= \\sum_{p \\in \\Omega} I_0(q - R_{-\\theta} p) K(p) \\\\\n&\\neq \\sum_{p \\in \\Omega} I_0(q - p) K(p) \\\\\n&= J_0(q).\n\\end{align*}\n\nIn other words, convolution is not rotation invariant. \\blacksquare"
  },
  {
    "objectID": "drafts/2024-08-09-cnn-rotation-invariant/index.html#convolutional-net-can-learn-to-be-translation-rotation-invariant",
    "href": "drafts/2024-08-09-cnn-rotation-invariant/index.html#convolutional-net-can-learn-to-be-translation-rotation-invariant",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "Convolutional net can learn to be translation & rotation invariant",
    "text": "Convolutional net can learn to be translation & rotation invariant\nSo the convolution operator is neither translation nor rotation invariant. So why did I say the the statement ‚Äúa convolutional neural network is not rotation invariant‚Äù is only partially true? It should be borderline false now, no? Well there‚Äôs a stark difference between a convolution operator and a convolutional neural net. The latter utilizes the convolution operator but is much more complex.\nA convolutional neural net typically composes of multiple kernel convolutions, pooling operators and activation functions. The activation function introduces non-linearity and the kernel convolutions are learnable but as we have seen, they are neither translation nor rotation invariant.\nSo if I tell you that a convolutional neural net can be translation and/or rotation invariant, where will your money be on? It should be on the pooling operator‚Ä¶ plus a sufficiently broad dataset. We will cover this in more detail in a later post."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "projects",
    "section": "",
    "text": "This project covers strategy research, experimentation (with reporting) and deployment via Google Cloud.\n\n\nResearched and verified the class weight strategy in ‚ÄúFraud Detection using Machine Learning‚Äù (Oza, 2018); and further extended the paper‚Äôs analysis with new models and metrics. I wrote a full experiment report on this strategy verification which can be found here: Replication & extension of ‚ÄúFraud Detection using Machine Learning‚Äù (Oza, 2018).\nTrained logistic regression, SVMs and decision trees to perform financial transactions fraud detection in an imbalanced dataset of 6+ million rows and 0.1% sample fraud transactions (Python, scikit-learn).\nBuilt a web app to visualise streaming transactions data and perform live fraud detection using trained models. (Python, Streamlit, Docker, Google Artifact Registry, Google Cloud Run, Google Cloud Pub/Sub, Google Vertex AI).\n\n\n\n\n\nProblem statement: How can we determine if the change in observed conversion rates after website redesign is not due to random chance? Moreover, can we get an exact probability of how likely a test group is to perform better/worse than the control group?\n\n\nIn this mini project, I analysed the conversion rates of four different user groups (one of which is the control group) using pivot tables and bar plots to get a first big picture.\nThen, using PyMC3, I applied Bayesian A/B testing based on a Metropolis sampler to measure which group is most likely to have a higher conversion rate than the control group. The Bayesian way yields a solid probability unlike the frequentist approach. For example, in this project, I was able to deduce that ‚Äúthere is a 99% probability that user group B has a higher conversion rate than the control group‚Äù.\nThis exact probability gives us the confidence required to make important business decisions. In this case, we can be really confident in our decision of switching to the design version exposed to group B since there is only a 1% chance of B being worse than the control. This is one of the many awesome reasons why I favor the Bayesian approach for data tasks; this also helps us answer the second problem.\n\nThis project is hosted on DataCamp Workspace.\n\n\n\n\nProblem statement: To what extent can we use a lightweight, explainable model to predict cycle hires with lowest RMSE?\nThe idea of the project is to understand trends in the usage of TfL Santander Cycles (aka Boris bikes) and then predict cycle hires using linear models which are scalable and lightweight. In this project, I have\n\nInvestigated suitability of fitting a linear model by checking existence of trends in the residuals vs fitted plot.\nVerified normality of cycle hires after Yeo-Johnson normalisation using a density, histogram and QQ plot.\nApplied feature engineering methods such as forward search model selection, one-hot encoding, moving average, and Yeo-Johnson normalisation.\nImplemented a linear model with 99% lower RMSE (935.5 to 3.5) and 155% higher R 2 score (0.27 to 0.69) relative to the baseline naive linear model.\n\nThis project was hosted on Deepnote and then hosted on DataCamp Workspace."
  },
  {
    "objectID": "projects.html#data-science",
    "href": "projects.html#data-science",
    "title": "projects",
    "section": "",
    "text": "This project covers strategy research, experimentation (with reporting) and deployment via Google Cloud.\n\n\nResearched and verified the class weight strategy in ‚ÄúFraud Detection using Machine Learning‚Äù (Oza, 2018); and further extended the paper‚Äôs analysis with new models and metrics. I wrote a full experiment report on this strategy verification which can be found here: Replication & extension of ‚ÄúFraud Detection using Machine Learning‚Äù (Oza, 2018).\nTrained logistic regression, SVMs and decision trees to perform financial transactions fraud detection in an imbalanced dataset of 6+ million rows and 0.1% sample fraud transactions (Python, scikit-learn).\nBuilt a web app to visualise streaming transactions data and perform live fraud detection using trained models. (Python, Streamlit, Docker, Google Artifact Registry, Google Cloud Run, Google Cloud Pub/Sub, Google Vertex AI).\n\n\n\n\n\nProblem statement: How can we determine if the change in observed conversion rates after website redesign is not due to random chance? Moreover, can we get an exact probability of how likely a test group is to perform better/worse than the control group?\n\n\nIn this mini project, I analysed the conversion rates of four different user groups (one of which is the control group) using pivot tables and bar plots to get a first big picture.\nThen, using PyMC3, I applied Bayesian A/B testing based on a Metropolis sampler to measure which group is most likely to have a higher conversion rate than the control group. The Bayesian way yields a solid probability unlike the frequentist approach. For example, in this project, I was able to deduce that ‚Äúthere is a 99% probability that user group B has a higher conversion rate than the control group‚Äù.\nThis exact probability gives us the confidence required to make important business decisions. In this case, we can be really confident in our decision of switching to the design version exposed to group B since there is only a 1% chance of B being worse than the control. This is one of the many awesome reasons why I favor the Bayesian approach for data tasks; this also helps us answer the second problem.\n\nThis project is hosted on DataCamp Workspace.\n\n\n\n\nProblem statement: To what extent can we use a lightweight, explainable model to predict cycle hires with lowest RMSE?\nThe idea of the project is to understand trends in the usage of TfL Santander Cycles (aka Boris bikes) and then predict cycle hires using linear models which are scalable and lightweight. In this project, I have\n\nInvestigated suitability of fitting a linear model by checking existence of trends in the residuals vs fitted plot.\nVerified normality of cycle hires after Yeo-Johnson normalisation using a density, histogram and QQ plot.\nApplied feature engineering methods such as forward search model selection, one-hot encoding, moving average, and Yeo-Johnson normalisation.\nImplemented a linear model with 99% lower RMSE (935.5 to 3.5) and 155% higher R 2 score (0.27 to 0.69) relative to the baseline naive linear model.\n\nThis project was hosted on Deepnote and then hosted on DataCamp Workspace."
  },
  {
    "objectID": "projects.html#research-ml",
    "href": "projects.html#research-ml",
    "title": "projects",
    "section": "üî¨ research ML",
    "text": "üî¨ research ML\n\nMSc thesis. ‚ÄúEnhancing VAE-learning on spatial priors using GCN‚Äù\nMy Oxford MSc thesis supervised by Seth Flaxman, Swapnil Mishra and Elizaveta Semenova.\n\nI made the observation that the PriorVAE framework in ‚ÄúPriorVAE: encoding spatial priors with variational autoencoders for small-area estimation‚Äù (Semenova et. al, 2022) does not make efficient use of the data‚Äôs local neighbourhood structure when learning spatial priors for MCMC sampling.\nSo I proposed a new framework, called PriorVGAE, which exploits the underlying local neighbourhood structure and propagates this information efficiently via the use of graph convolutional networks (GCN). Under this new framework, we were able to perform MCMC inference with far superior performance as compared to PriorVAE while enjoying better sampling speeds. We achieved lower mean squared error (MSE) for our sample reconstructions across all our experiments and attained higher effective sample sizes with lower MCMC sampling time.\nThe breakthrough. Naively injecting a GCN into a VAE framework would not make the architecture work. The key observation was to realize that spatial priors inherently admits global information. To this end, I introduced a local-to-global scheme that consolidates all the local information into a global representation, relying on the universal approximator theorem of MLPs, to efficiently learn the spatial priors.\nSome bonus advantages of this framework as compared to PriorVAE include getting computationally cheaper training. We now have fewer learnable parameters since we replace MLPs with GCNs and GCN weights are shared across the support. Out-of-sample predictions are also now tractable as restarting compute training is relatively inexpensive.\n\n\n\nReproduction of ‚ÄúInference Suboptimality in Variational Autoencoders‚Äù (Cremer et. al, 2018) in JAX\nWe reproduced some of the key interesting experiments in the paper ‚ÄúInference Suboptimality in Variational Autoencoders‚Äù (Cremer et. al, 2018) using JAX and extended the result to the K-MNIST dataset. This work was done jointly with Basim Khajwal, Snehal Raj and Vasileios Ntogram.\n\n\n\n\nReproduction of ‚ÄúVariational Graph Auto-Encoders‚Äù (Kipf and Welling, 2016) in JAX\nI reproduced the variational graph autoencoder (VGAE) deep learning model using JAX to be used as a component in my MSc thesis."
  },
  {
    "objectID": "projects.html#web-app",
    "href": "projects.html#web-app",
    "title": "projects",
    "section": "üíª web app",
    "text": "üíª web app\n\nTradeLogger\nThis project is written in Python using the Flask framework. One of the problems with stock traders is that they do not keep the big picture of where they are in their trading journey. For example. if they are losing, do they realise that they are losing 5 trades consecutively? This tool is designed for traders to trade better. A machine learning pipeline is also added to learn the time series pattern of whether the trader has a good chance on the next trade given the outcomes of the previous trades.\n\n\n\n\nallpow\nThis project is written in Python using Streamlit. It is a simple calculator to estimate one‚Äôs monthly budget (in London by default). I originally made it to help my fellow Malaysian students who are coming to London for the first time organise their finances better. The first problem of coming to a new country far away from home (and also most probably first time renting a property in their life) is to estimate the prices of groceries, transport, rent and the like. This calculator solves that problem.\nLink to the deployed calculator: click here"
  },
  {
    "objectID": "projects.html#utilities",
    "href": "projects.html#utilities",
    "title": "projects",
    "section": "üîß utilities",
    "text": "üîß utilities\n\nEasyPS\nA simple, out of the box personal statement LaTeX framework. It helps handling duplicated tex files when writing personal statements for multiple universities, scholarships or jobs.\n\n\n\n\nPyEasyPS\nPyEasyPS is EasyPS (see above) ported to Python. It is even easier to use since the manual processes required in EasyPS (e.g.¬†error-handling, targeted-updating of personal statements) are done for you. Essentially, it lets you focus on what‚Äôs most important ‚Äì your personal statement content."
  },
  {
    "objectID": "projects.html#open-source",
    "href": "projects.html#open-source",
    "title": "projects",
    "section": "üì≠ open source",
    "text": "üì≠ open source\n\nJraph\nI am a key contributor of Jraph which is Google DeepMind‚Äôs open source library for graph neural networks using JAX."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "I am a Senior Data Scientist at Dyson, helping decision making at the highest level in Dyson‚Äôs new Home Business Unit. I spend my 9-5 dealing with Python, SQL, PySpark, GCP (BigQuery, DataProc, Pub/Sub, App Engine, Vertex AI, among others), on top of mentoring and leading the data scientists in my team.\nPrior to work, I studied Mathematics at King‚Äôs College London, and then went on to study Computer Science at the University of Oxford where I was awarded an MSc.\nWhen I‚Äôm not writing code, I like to explore new hobbies. Most recently, I picked up cycling and running. I enjoy good acoustic music and am always down for a game of table tennis or poker.\nMy tech stack has changed over the years, with some technologies I haven‚Äôt used for quite a while now. This is a good overview of what I still have in my mind:\n\nProgramming languages: Python, R, C/C++ (prior experience), Swift (prior experience).\nData analysis: SQL, PySpark, PyData stack, Plotly, NetworkX, Google BigQuery, AWS Redshift (yes, I‚Äôve used both).\nML & stats modelling: scikit-learn, statsmodels, scipy, PyMC3, PyTorch, Jax\nWeb & dashboard: HTML/CSS/JavaScript, Tableau, ReactJS, Flask, Streamlit\nDeployment: Git, Docker, Google Cloud Platform (GCP) stack, AWS Redshift\nOthers: LaTeX"
  },
  {
    "objectID": "drafts/2024-08-09-cnn-rotation-invariant/index.html#seems-like-convolutional-neural-nets-are-not-rotation-invariant-at-all",
    "href": "drafts/2024-08-09-cnn-rotation-invariant/index.html#seems-like-convolutional-neural-nets-are-not-rotation-invariant-at-all",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "Seems like convolutional neural nets are not rotation invariant at all‚Ä¶?",
    "text": "Seems like convolutional neural nets are not rotation invariant at all‚Ä¶?\nSo the convolution operator is neither translation nor rotation invariant. So why did I say the statement ‚Äúa convolutional neural network is not rotation invariant‚Äù is only partially true? It should be borderline false now, no? Well there‚Äôs a stark difference between a convolution operator and a convolutional neural net. What we have shown is that the former is not translation/rotation invariant but the latter is a different beast completely, it is much more complex.\nA convolutional neural net typically composes of multiple kernel convolution operators, pooling operators and activation functions. See the difference now? A convolutional neural net has a convolution operator as a layer. So in its most basic form where the net only has convolutional layers, it is neither translation nor rotation invariant. But‚Ä¶ since we have other layers, we can actually make the net learn these invariances by combining the right layers (and the right data).\nAs in MLPs, the activation function introduces non-linearity so it‚Äôs not really a bonus. So based on the layers I have mentioned, it should be obvious now. A convolutional operator and the activation function themselves alone will not be helpful; so the secret sauce must be the pooling operator‚Ä¶ plus a sufficiently broad dataset. I‚Äôll prove why this is true in a later post."
  },
  {
    "objectID": "posts/2024-08-09-cnn-rotation-invariant/index.html",
    "href": "posts/2024-08-09-cnn-rotation-invariant/index.html",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "",
    "text": "‚ÄúWhy is a convolutional neural network not rotation invariant?‚Äù.\nThis question popped up in an interview recently, and it is surprisingly deeper than I initially thought. For a start, the statement ‚Äúa convolutional neural network is not rotation invariant‚Äù is not entirely true, but only half-true, maybe a quarter-true. So why is this a popular statement being asked in the machine learning domain? I feel like this is mainly due to a poor understanding of the convolutional neural net architecture.\nWhat‚Äôs surprising is how little I have been able to find on the internet about this question. The articles that I have found are unoriginal and poor derivatives of what was written in (Goodfellow, Bengio, and Courville 2016); and like any good mathematics textbook, they do not really do a deep dive into the mathematical reasoning behind the statement ‚Äì which make interpretations written around it even worse. In fact, Goodfellow, Bengio, and Courville (2016) mentions that a convolutional neural net is rotation invariant with the right layers‚Ä¶ so what the heck is going on here?\nToday, I am putting this question to bed with a somewhat acceptable mathematical reasoning. Let‚Äôs get one important thing out of the way first because this might confuse some people. The statement ‚Äúconvolutional net is not rotation invariant‚Äù is somewhat misleading; and this is a consequence of people not understanding the difference betwen a convolutional neural net, a convolutional layer and a convolutional operator. So what is actually ‚Äúconvolution‚Äù in convolutional neural net?"
  },
  {
    "objectID": "posts/2024-08-09-cnn-rotation-invariant/index.html#what-is-actually-a-convolutional-neural-net",
    "href": "posts/2024-08-09-cnn-rotation-invariant/index.html#what-is-actually-a-convolutional-neural-net",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "What is actually a convolutional neural net?",
    "text": "What is actually a convolutional neural net?\nA convolutional neural network is simply a neural network where at least one of its layers utilize the convolutional operator rather than a full-blown matrix multiplication (Goodfellow, Bengio, and Courville 2016). This definition is so general that it renders the statement ‚Äúwhy is a convolutional neural network (CNN) not rotation invariant?‚Äù to be false, especially with our breadth of understanding on deep learning today. I will demonstrate why precisely in the rest of this article.\nSo let‚Äôs go down one step in the rabbit hole‚Ä¶ what is a convolution? A convolution * of two complex-valued functions I and K is simply the integral transform\nJ(t) := (I * K)(t) = \\int_{\\mathbb{R}^d} I(\\tau) K(t - \\tau) d\\tau = \\int_{\\mathbb{R}^d} I(t - \\tau) K(t) d\\tau.\nIn computer vision, we are, at the most basic level, concerned with the discrete convolution of real-valued objects (i.e.¬†images) over a finite two-dimensional integer support. Although, this is not exactly true because with modern convolutional neural nets, you actually perform multi-channel convolution which is typically modelled with a four-dimensional kernel tensor instead. Let‚Äôs focus only on the basics though. In the two-dimensional case, the convolution above reduces (and simplifies) to\nJ[i, j] = \\sum_{m, n} I[i- m, j- n] K[m, n],\nwhere I, K are real-valued functions over \\mathbb{Z}^2 and the summation is done over the support of K. Here, I use square brackets instead of parentheses to align with literature on discrete convolution.\nNow, I claim that the convolution operator is not rotation invariant. But before that, let‚Äôs look at something even simpler. I claim that the convolution operator is not even translation invariant!"
  },
  {
    "objectID": "posts/2024-08-09-cnn-rotation-invariant/index.html#convolution-is-not-translation-invariant",
    "href": "posts/2024-08-09-cnn-rotation-invariant/index.html#convolution-is-not-translation-invariant",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "Convolution is not translation invariant",
    "text": "Convolution is not translation invariant\nTo prove that convolution is not translation invariant, it suffices to look at a single nonzero shift s in the x-coordinate where we observe that\n\n\\begin{align*}\nJ[i, j]\n&= \\sum_{m, n} I[i-m, j-n] K[m, n] \\\\\n&\\neq \\sum_{m, n} I[i-m+s, j-n] K[m, n] \\\\\n&= J[i + s, j].\n\\end{align*}\n\nObviously, this is a sum of (a lot of) product terms so there are several ways where equality J[i,j] = J[i + s, j] can be achieved; but it is not a guarantee. \\blacksquare\nHere‚Äôs a simple concrete example to see where they are not equal. Define I to be the function [m, n] \\mapsto 1 and let K be defined by\n\n[m, n] \\mapsto\n\\begin{cases}\n1 & \\text{if } m = n \\text{ and } m, n \\neq 0, \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\nover \\{ 0, 1, 2\\} \\times \\{ 0, 1, 2 \\} \\subseteq \\mathbb{Z}^2. Then evaluating J at (i, j) = (0, 1) gives J[i, j] = 0 but J[i+1, j] = 1.\nNow was that surprising? Did you feel lied to all your life that convolutional neural nets are translation invariant? Well, we‚Äôll get to why that statement is commonly made later at the end of this post. For now, let me show you that the convolution operator is not rotation invariant."
  },
  {
    "objectID": "posts/2024-08-09-cnn-rotation-invariant/index.html#convolution-is-not-rotation-invariant",
    "href": "posts/2024-08-09-cnn-rotation-invariant/index.html#convolution-is-not-rotation-invariant",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "Convolution is not rotation invariant",
    "text": "Convolution is not rotation invariant\nNow that you‚Äôve got a basic idea on how to disprove convolution being translation invariant, it should be straightforward to see that convolution is not rotation invariant‚Ä¶ at least a sketch proof should be present in your mind. Reasoning it formally, however, takes a bit more effort as we need to do some setup first. For a start, I am going to make things simple by expanding the domain back to \\mathbb{R}^2 because I do not want to talk about rotation matrices in \\mathbb{Z}^2 which is not pretty. As a bonus to doing this, we are now back in the world of vector spaces‚Ä¶ although we can always make an extra effort and start talking about \\mathbb{Z}^2 as a module over itself. Let‚Äôs now start putting the pieces together.\nLet p_{\\mathrm{center}} = (0, 0) \\in \\mathbb{R}^2 be the image center; then define a two-dimensional Cartesian coordinate system centered at p_{\\mathrm{center}} and fix the standard basis. This defines the axes that we will play around to perform rotation. Now that we have that set up, for any vector x \\in \\mathbb{R}^2, we can perform a counterclockwise rotation of \\theta degrees around p_{\\mathrm{center}} by applying the rotation matrix\nR_\\theta = \\begin{pmatrix} \\cos \\theta & -\\sin \\theta \\\\ \\sin \\theta & \\cos \\theta \\end{pmatrix}.\nThen for an image I_0(x): \\mathcal{D} \\subseteq \\mathbb{R}^2 \\to \\mathbb{R}, the corresponding image I_\\theta rotated by \\theta degrees around p_{\\mathrm{center}} is given by the image I_\\theta(y): \\mathcal{D}' \\subseteq \\mathbb{R}^2 \\to \\mathbb{R} where I_\\theta(y) = I_0(x) and y = R_\\theta x (or equivalently, x = R_\\theta^{-1} y).\nNow fix a finite canvas to draw our images on so let \\Omega \\subseteq \\mathbb{R}^2 be a bounded domain such that \\mathcal{D}, \\mathcal{D'} \\subseteq \\Omega. Suppose now that the point q \\in \\mathcal{D} is mapped (bijectively) to q' \\in \\mathcal{D}' under the rotation R_\\theta. Then we can now see that the convolution with rotation is not equal to the convolution without rotation as follows\n\n\\begin{align*}\nJ_\\theta(q') &= \\sum_{p \\in \\Omega} I_{\\theta}(q'-p) K(p) \\\\\n&= \\sum_{p \\in \\Omega} I_0(R_{-\\theta} q' - R_{-\\theta} p) K(p) \\\\\n&= \\sum_{p \\in \\Omega} I_0(q - R_{-\\theta} p) K(p) \\\\\n&\\neq \\sum_{p \\in \\Omega} I_0(q - p) K(p) \\\\\n&= J_0(q).\n\\end{align*}\n\nIn other words, convolution is not rotation invariant. \\blacksquare"
  },
  {
    "objectID": "posts/2024-08-09-cnn-rotation-invariant/index.html#seems-like-convolutional-neural-nets-are-not-rotation-invariant-at-all",
    "href": "posts/2024-08-09-cnn-rotation-invariant/index.html#seems-like-convolutional-neural-nets-are-not-rotation-invariant-at-all",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "Seems like convolutional neural nets are not rotation invariant at all‚Ä¶?",
    "text": "Seems like convolutional neural nets are not rotation invariant at all‚Ä¶?\nSo the convolution operator is neither translation nor rotation invariant. So why did I say the statement ‚Äúa convolutional neural network is not rotation invariant‚Äù is only partially true? It should be borderline false now, no? Well there‚Äôs a stark difference between a convolution operator and a convolutional neural net. What we have shown is that the former is not translation/rotation invariant but the latter is a different beast completely, it is much more complex.\nA convolutional neural net typically composes of multiple kernel convolution operators, pooling operators and activation functions. See the difference now? A convolutional neural net has a convolution operator as a layer. So in its most basic form where the net only has convolutional layers, it is neither translation nor rotation invariant. But‚Ä¶ since we have other layers, we can actually make the net learn these invariances by combining the right layers (and the right data).\nAs in MLPs, the activation function introduces non-linearity so it‚Äôs not really a bonus. So based on the layers I have mentioned, it should be obvious now. A convolutional operator and the activation function themselves alone will not be helpful; so the secret sauce must be the pooling operator‚Ä¶ plus a sufficiently broad dataset. I‚Äôll prove why this is true in a later post."
  },
  {
    "objectID": "posts/2024-08-09-cnn-rotation-invariant/index.html#convolutional-neural-net-convolution-operators",
    "href": "posts/2024-08-09-cnn-rotation-invariant/index.html#convolutional-neural-net-convolution-operators",
    "title": "Convolutional neural networks are not rotation invariant‚Ä¶ since when?",
    "section": "Convolutional neural net, convolution operators",
    "text": "Convolutional neural net, convolution operators\nA convolutional neural network is simply a neural network where at least one of its layers utilize the convolutional operator rather than a full-blown matrix multiplication (Goodfellow, Bengio, and Courville 2016). This definition is so general that it renders the statement ‚Äúwhy is a convolutional neural network (CNN) not rotation invariant?‚Äù to be false, especially with our breadth of understanding on deep learning today. I will demonstrate why precisely in the rest of this article.\nSo let‚Äôs go down one step in the rabbit hole‚Ä¶ what is a convolution? A convolution * of two complex-valued functions I and K is simply the integral transform\nJ(t) := (I * K)(t) = \\int_{\\mathbb{R}^d} I(\\tau) K(t - \\tau) d\\tau = \\int_{\\mathbb{R}^d} I(t - \\tau) K(t) d\\tau.\nIn computer vision, we are, at the most basic level, concerned with the discrete convolution of real-valued objects (i.e.¬†images) over a finite two-dimensional integer support. Although, this is not exactly true because with modern convolutional neural nets, you actually perform multi-channel convolution which is typically modelled with a four-dimensional kernel tensor instead. Let‚Äôs focus only on the basics though. In the two-dimensional case, the convolution above reduces (and simplifies) to\nJ[i, j] = \\sum_{m, n} I[i- m, j- n] K[m, n],\nwhere I, K are real-valued functions over \\mathbb{Z}^2 and the summation is done over the support of K. Here, I use square brackets instead of parentheses to align with literature on discrete convolution.\nNow, I claim that the convolution operator is not rotation invariant. But before that, let‚Äôs look at something even simpler. I claim that the convolution operator is not even translation invariant!"
  }
]